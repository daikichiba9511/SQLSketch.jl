var documenterSearchIndex = {"docs":
[{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api/#Query-Building","page":"API Reference","title":"Query Building","text":"","category":"section"},{"location":"api/#Starting-Queries","page":"API Reference","title":"Starting Queries","text":"","category":"section"},{"location":"api/#Filtering-and-Conditions","page":"API Reference","title":"Filtering and Conditions","text":"","category":"section"},{"location":"api/#Selecting-Columns","page":"API Reference","title":"Selecting Columns","text":"","category":"section"},{"location":"api/#Ordering-and-Limiting","page":"API Reference","title":"Ordering and Limiting","text":"","category":"section"},{"location":"api/#Grouping","page":"API Reference","title":"Grouping","text":"","category":"section"},{"location":"api/#DML-Operations","page":"API Reference","title":"DML Operations","text":"","category":"section"},{"location":"api/#INSERT","page":"API Reference","title":"INSERT","text":"","category":"section"},{"location":"api/#Batch-INSERT","page":"API Reference","title":"Batch INSERT","text":"For efficient insertion of large datasets, use insert_batch:\n\nPerformance:\n\nSQLite: 1.35x - 299x faster than loop INSERT\nPostgreSQL: 4x - 2016x faster (uses COPY FROM STDIN)\n\nExample:\n\n# Prepare data\nusers = [\n    (id=1, email=\"alice@example.com\", active=true),\n    (id=2, email=\"bob@example.com\", active=true),\n    # ... thousands more\n]\n\n# Batch insert (automatically optimized)\nresult = insert_batch(conn, dialect, registry, :users,\n                      [:id, :email, :active], users)\nprintln(\"Inserted $(result.rowcount) rows\")\n\nSee benchmark/RESULTS.md in the repository for detailed performance analysis.","category":"section"},{"location":"api/#UPDATE","page":"API Reference","title":"UPDATE","text":"","category":"section"},{"location":"api/#DELETE","page":"API Reference","title":"DELETE","text":"","category":"section"},{"location":"api/#RETURNING","page":"API Reference","title":"RETURNING","text":"","category":"section"},{"location":"api/#DDL-Operations","page":"API Reference","title":"DDL Operations","text":"","category":"section"},{"location":"api/#Table-Operations","page":"API Reference","title":"Table Operations","text":"","category":"section"},{"location":"api/#Index-Operations","page":"API Reference","title":"Index Operations","text":"","category":"section"},{"location":"api/#Expressions","page":"API Reference","title":"Expressions","text":"","category":"section"},{"location":"api/#Column-References","page":"API Reference","title":"Column References","text":"","category":"section"},{"location":"api/#Literals-and-Parameters","page":"API Reference","title":"Literals and Parameters","text":"","category":"section"},{"location":"api/#Comparisons","page":"API Reference","title":"Comparisons","text":"Binary operators are overloaded for SQLExpr:\n\n==, != - Equality/inequality\n<, <=, >, >= - Comparison\n+, -, *, / - Arithmetic\n& (and), | (or) - Logical operators","category":"section"},{"location":"api/#Type-Conversion","page":"API Reference","title":"Type Conversion","text":"","category":"section"},{"location":"api/#Subqueries","page":"API Reference","title":"Subqueries","text":"","category":"section"},{"location":"api/#Query-Execution","page":"API Reference","title":"Query Execution","text":"SQLSketch separates data retrieval from side-effecting operations.\n\nKey distinction:\n\nUse fetch_* when you want to retrieve data (SELECT, INSERT/UPDATE/DELETE with RETURNING)\nUse execute when you want to produce side effects without retrieving data (INSERT, UPDATE, DELETE, CREATE TABLE, etc.)\n\nQuick reference:\n\nFunction Returns Use Case Performance\nfetch_all(conn, query) Vector{T} Get all rows (row-based) Fast (40-155% overhead vs raw)\nfetch_all_columnar(conn, query) NamedTuple of Vectors Get all rows (columnar) Fastest (4-12% overhead vs raw)\nfetch_all_columnar(conn, query, ColumnarType) ColumnarType Get all rows (type-safe columnar) Fastest + type-safe\nfetch_one(conn, query) T Get exactly one row (error if 0 or >1) -\nfetch_maybe(conn, query) Union{T, Nothing} Get optional row -\nexecute(conn, query) Int64 Perform side effects (returns affected row count) -\n\nSee Design - Query Execution Model for detailed rationale.","category":"section"},{"location":"api/#Fetching-Results","page":"API Reference","title":"Fetching Results","text":"","category":"section"},{"location":"api/#Row-Based-API","page":"API Reference","title":"Row-Based API","text":"Performance characteristics (PostgreSQL):\n\nResult Size Time Overhead vs Raw LibPQ\n500 rows ~327 μs 40%\n1667 rows ~2.5 ms 155%\n\nWhen to use:\n\n✅ CRUD operations (iterate over individual records)\n✅ Small to medium result sets (<10,000 rows)\n✅ Row-by-row processing is natural","category":"section"},{"location":"api/#Columnar-API-(PostgreSQL-Only)","page":"API Reference","title":"Columnar API (PostgreSQL Only)","text":"Note: fetch_all_columnar is a PostgreSQL-specific optimization. See PostgreSQL driver documentation for details.\n\nPerformance characteristics (PostgreSQL):\n\nResult Size Time Overhead vs Raw LibPQ\n500 rows ~252 μs 12%\n1667 rows ~1.1 ms 6%\n\nSpeedup vs row-based: 8-10x faster\n\nWhen to use:\n\n✅ Analytics queries (aggregations, statistics)\n✅ Large result sets (>1,000 rows)\n✅ Column-wise operations (sum, mean, filter)\n✅ DataFrame/CSV export\n✅ Data science workflows\n\nUsage:\n\n# Option 1: NamedTuple of Vectors (flexible)\nresult = fetch_all_columnar(conn, dialect, registry, query)\n# → (id = [1, 2, 3, ...], amount = [100.0, 200.0, ...])\ntotal = sum(result.amount)\n\n# Option 2: Type-safe columnar struct (recommended for production)\nstruct SalesColumnar\n    id::Vector{Int}\n    amount::Vector{Float64}\nend\n\nresult = fetch_all_columnar(conn, dialect, registry, query, SalesColumnar)\n# → SalesColumnar([1, 2, 3, ...], [100.0, 200.0, ...])\ntotal = sum(result.amount)  # Type-safe!","category":"section"},{"location":"api/#Executing-Statements","page":"API Reference","title":"Executing Statements","text":"","category":"section"},{"location":"api/#Transactions","page":"API Reference","title":"Transactions","text":"","category":"section"},{"location":"api/#SQL-Generation","page":"API Reference","title":"SQL Generation","text":"","category":"section"},{"location":"api/#Metadata-API","page":"API Reference","title":"Metadata API","text":"SQLSketch provides introspection APIs to query database schema metadata:","category":"section"},{"location":"api/#Database-Schema-Inspection","page":"API Reference","title":"Database Schema Inspection","text":"Example:\n\n# List all tables in current database\ntables = list_tables(conn)\n# → [\"orders\", \"products\", \"users\"]\n\n# Get table structure\ncolumns = describe_table(conn, :users)\nfor col in columns\n    println(\"$(col.name): $(col.type) $(col.nullable ? \"NULL\" : \"NOT NULL\")\")\nend\n# → id: INT NOT NULL [PK]\n# → email: VARCHAR(255) NOT NULL\n# → name: VARCHAR(255) NOT NULL\n# → age: INT NULL\n# → created_at: DATETIME NULL\n\n# List all schemas/databases\nschemas = list_schemas(conn)\n# → [\"myapp_dev\", \"myapp_test\", \"myapp_prod\"]\n\nMySQL-specific notes:\n\nlist_tables() excludes system tables automatically\nlist_schemas() excludes information_schema, mysql, performance_schema, sys\ndescribe_table() returns MySQL-specific type names (e.g., TINYINT(1), VARCHAR(255))","category":"section"},{"location":"api/#Dialects","page":"API Reference","title":"Dialects","text":"SQLSketch provides dialect abstraction for different SQL databases:\n\nSQLiteDialect - SQLite SQL generation\nPostgreSQLDialect - PostgreSQL SQL generation\nMySQLDialect - MySQL/MariaDB SQL generation\n\nEach dialect handles:\n\nIdentifier quoting (\"identifier\" for PostgreSQL, identifier for MySQL/SQLite)\nPlaceholder syntax ($1, $2, ... for PostgreSQL, ? for MySQL/SQLite)\nType mapping and casting\nSQL feature capabilities (RETURNING, ON CONFLICT, etc.)","category":"section"},{"location":"api/#Drivers","page":"API Reference","title":"Drivers","text":"SQLSketch provides driver abstraction for database connections:\n\nSQLiteDriver - SQLite database driver (in-memory or file-based)\nPostgreSQLDriver - PostgreSQL database driver (via LibPQ.jl)\nMySQLDriver - MySQL/MariaDB database driver (via MySQL.jl)\n\nEach driver handles:\n\nConnection management\nQuery execution\nTransaction support\nParameter binding\nResult mapping\nPrepared statement caching (MySQL, PostgreSQL)","category":"section"},{"location":"api/#MySQL-Driver-Features","page":"API Reference","title":"MySQL Driver Features","text":"JSON Support:\n\nMySQL 5.7+ provides native JSON type support via the JSONCodec:\n\nusing SQLSketch.Codecs.MySQL\n\n# Register MySQL codecs (includes JSON support)\nregistry = CodecRegistry()\nMySQL.register_mysql_codecs!(registry)\n\n# JSON data is automatically encoded/decoded\nmetadata = Dict(\"role\" => \"admin\", \"permissions\" => [\"read\", \"write\"])\nexecute_sql(conn, \"INSERT INTO users (email, metadata) VALUES (?, ?)\",\n           [\"user@example.com\", JSON3.write(metadata)])\n\n# Retrieve JSON\nrows = fetch_all(conn, dialect, registry, query)\njson_data = JSON3.read(rows[1].metadata, Dict{String, Any})\n\nPrepared Statement Caching:\n\nMySQL driver includes LRU-based prepared statement caching for improved performance:\n\n# Prepared statements are automatically cached\nq = from(:users) |>\n    where(col(:users, :id) == param(Int, :id)) |>\n    select(NamedTuple, col(:users, :email))\n\n# First execution - cache miss, statement prepared\nresult1 = fetch_all(conn, dialect, registry, q, (id=1,); use_prepared=true)\n\n# Second execution - cache hit, reuses prepared statement\nresult2 = fetch_all(conn, dialect, registry, q, (id=2,); use_prepared=true)\n\nPerformance benefits:\n\n10-20% faster for repeated queries\nReduced MySQL server load (no re-parsing)\nLRU eviction prevents memory bloat\nThread-safe for single-connection use\n\nConfiguration:\n\n# Custom cache size\nraw_conn = DBInterface.connect(MySQL.Connection, host, user, password; db=db)\nconn = MySQLConnection(raw_conn; cache_size=200, enable_cache=true)\n\n# Disable caching\nconn = MySQLConnection(raw_conn; enable_cache=false)","category":"section"},{"location":"api/#Migration-System","page":"API Reference","title":"Migration System","text":"","category":"section"},{"location":"api/#SQLSketch.Core.from","page":"API Reference","title":"SQLSketch.Core.from","text":"from(table::Symbol) -> From{NamedTuple}\n\nCreates a FROM clause as the starting point of a query.\n\nExample\n\nq = from(:users)\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.where","page":"API Reference","title":"SQLSketch.Core.where","text":"where(q, condition)\n\nAdds a WHERE clause to filter rows.\n\nThis is a shape-preserving operation.\n\nCan be used in two ways:\n\nExplicit: where(query, condition)\nPipeline: query |> where(condition)\n\nThe curried form where(condition) returns a function suitable for pipeline composition.\n\nExample\n\n# Pipeline style\nq = from(:users) |> where(col(:users, :active) == literal(true))\n\n# Explicit style\nq = where(from(:users), col(:users, :active) == literal(true))\n\n\n\n\n\nwhere(source::UpdateSet{T}, condition::SQLExpr) -> UpdateWhere{T}\n\nAdd WHERE clause to UPDATE (explicit version).\n\n\n\n\n\nwhere(source::DeleteFrom{T}, condition::SQLExpr) -> DeleteWhere{T}\n\nAdd WHERE clause to DELETE (explicit version).\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.having","page":"API Reference","title":"SQLSketch.Core.having","text":"having(q::Query{T}, condition::SQLExpr)::Having{T}\n\nAdds a HAVING clause (used with GROUP BY).\n\nThis is a shape-preserving operation.\n\nCan be used in two ways:\n\nExplicit: having(query, condition)\nPipeline: query |> having(condition)\n\nThe curried form having(condition) returns a function suitable for pipeline composition.\n\nExample\n\nq = from(:orders) |>\n    group_by(col(:orders, :user_id)) |>\n    having(func(:COUNT, [col(:orders, :id)]) > literal(5))\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.select","page":"API Reference","title":"SQLSketch.Core.select","text":"select(q::Query, OutT::Type, fields::SQLExpr...) -> Select{OutT}\n\nAdds a SELECT clause to project specific columns.\n\nThis is the only shape-changing operation – it changes the output type to OutT.\n\nCan be used in two ways:\n\nExplicit: select(query, OutT, fields...)\nPipeline: query |> select(OutT, fields...)\n\nThe curried form select(OutT, fields...) returns a function suitable for pipeline composition.\n\nExample\n\n# Pipeline style\nq = from(:users) |> select(NamedTuple, col(:users, :id), col(:users, :email))\n\n# Explicit style\nq = select(from(:users), NamedTuple, col(:users, :id), col(:users, :email))\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.distinct","page":"API Reference","title":"SQLSketch.Core.distinct","text":"distinct(q::Query{T}) -> Distinct{T}\n\nAdds a DISTINCT clause.\n\nThis is a shape-preserving operation.\n\nExample\n\nq = from(:users) |> select(NamedTuple, col(:users, :email)) |> distinct\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.order_by","page":"API Reference","title":"SQLSketch.Core.order_by","text":"order_by(q::Query{T}, field::SQLExpr; desc::Bool=false)::OrderBy{T}\n\nAdds an ORDER BY clause.\n\nThis is a shape-preserving operation.\n\nCan be used in two ways:\n\nExplicit: order_by(query, field, desc=false)\nPipeline: query |> order_by(field, desc=false)\n\nThe curried form order_by(field; desc=false) returns a function suitable for pipeline composition.\n\nExample\n\n# Pipeline style\nq = from(:users) |> order_by(col(:users, :created_at); desc = true)\n\n# Explicit style\nq = order_by(from(:users), col(:users, :created_at); desc = true)\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.limit","page":"API Reference","title":"SQLSketch.Core.limit","text":"limit(q::Query{T}, n::Int)::Limit{T}\n\nAdds a LIMIT clause.\n\nThis is a shape-preserving operation.\n\nCan be used in two ways:\n\nExplicit: limit(query, n)\nPipeline: query |> limit(n)\n\nThe curried form limit(n) returns a function suitable for pipeline composition.\n\nExample\n\nq = from(:users) |> limit(10)\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.offset","page":"API Reference","title":"SQLSketch.Core.offset","text":"offset(q::Query{T}, n::Int)::Offset{T}\n\nAdds an OFFSET clause.\n\nThis is a shape-preserving operation.\n\nCan be used in two ways:\n\nExplicit: offset(query, n)\nPipeline: query |> offset(n)\n\nThe curried form offset(n) returns a function suitable for pipeline composition.\n\nExample\n\nq = from(:users) |> offset(20)\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.group_by","page":"API Reference","title":"SQLSketch.Core.group_by","text":"group_by(q::Query{T}, fields::SQLExpr...)::GroupBy{T}\n\nAdds a GROUP BY clause.\n\nThis is a shape-preserving operation.\n\nCan be used in two ways:\n\nExplicit: group_by(query, fields...)\nPipeline: query |> group_by(fields...)\n\nThe curried form group_by(fields...) returns a function suitable for pipeline composition.\n\nExample\n\nq = from(:orders) |> group_by(col(:orders, :user_id))\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.insert_into","page":"API Reference","title":"SQLSketch.Core.insert_into","text":"insert_into(table::Symbol, columns::Vector{Symbol}) -> InsertInto{NamedTuple}\n\nCreate an INSERT INTO clause.\n\nExample\n\nq = insert_into(:users, [:name, :email]) |>\n    values([[literal(\"Alice\"), literal(\"alice@example.com\")]])\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.insert_batch","page":"API Reference","title":"SQLSketch.Core.insert_batch","text":"insert_batch(conn::Connection,\n             dialect::Dialect,\n             registry::CodecRegistry,\n             table::Symbol,\n             columns::Vector{Symbol},\n             rows::Vector{<:NamedTuple};\n             chunk_size::Int = 1000) -> ExecResult\n\nInsert multiple rows into a table using the most efficient method available.\n\nAutomatically selects the optimal insertion strategy:\n\nPostgreSQL with CAPBULKCOPY: Uses COPY FROM STDIN (fastest)\nOther databases: Uses multi-row INSERT VALUES (fast)\n\nArguments\n\nconn: Active database connection\ndialect: Dialect for SQL generation\nregistry: CodecRegistry for value encoding\ntable: Target table name\ncolumns: Column names to insert (must match NamedTuple keys)\nrows: Vector of NamedTuples containing row data\nchunk_size: Number of rows per transaction (default: 1000)\n\nReturns\n\nExecResult with rows_affected count\n\nPerformance\n\nPostgreSQL COPY (CAPBULKCOPY):\n\n50K-100K rows/sec\nIdeal for >10K rows\nBinary protocol (minimal overhead)\n\nStandard Batch INSERT:\n\n5K-20K rows/sec\nIdeal for <10K rows\nMulti-row VALUES clause\n\nExample\n\nusing SQLSketch\n\n# Connect\nconn = connect(PostgreSQLDriver(), \"postgresql://localhost/mydb\")\ndialect = PostgreSQLDialect()\nregistry = CodecRegistry()\n\n# Prepare data\nusers = [(id = 1, email = \"alice@example.com\", active = true),\n         (id = 2, email = \"bob@example.com\", active = true)\n         # ... 100K more rows\n         ]\n\n# Batch insert (automatically uses COPY for PostgreSQL)\nresult = insert_batch(conn, dialect, registry, :users, [:id, :email, :active], users)\nprintln(\"Inserted $(result.rows_affected) rows\")\n\nImplementation Details\n\nThe function detects PostgreSQL connections with COPY support:\n\nif supports(dialect, CAP_BULK_COPY) && conn isa PostgreSQLConnection\n    # Fast path: PostgreSQL COPY\n    _insert_batch_copy(conn, dialect, registry, table, columns, rows)\nelse\n    # Standard path: Multi-row INSERT\n    _insert_batch_standard(conn, dialect, registry, table, columns, rows, chunk_size)\nend\n\nError Handling\n\nEach chunk runs in a transaction\nRollback on failure (no partial chunks)\nError message includes failing row index\n\nChunking\n\nLarge batches are automatically split into chunks:\n\nDefault: 1000 rows per chunk\nEach chunk = separate transaction\nTotal rows_affected = sum of all chunks\n\nType Safety\n\nAll values are encoded using the CodecRegistry:\n\nAutomatic type conversion\nNULL/Missing handling\nType validation\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.update","page":"API Reference","title":"SQLSketch.Core.update","text":"update(table::Symbol) -> Update{NamedTuple}\n\nCreate an UPDATE statement.\n\nExample\n\nq = update(:users) |>\n    set(:name => param(String, :name)) |>\n    where(col(:users, :id) == param(Int, :id))\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.delete_from","page":"API Reference","title":"SQLSketch.Core.delete_from","text":"delete_from(table::Symbol) -> DeleteFrom{NamedTuple}\n\nCreate a DELETE FROM statement.\n\nExample\n\nq = delete_from(:users) |>\n    where(col(:users, :id) == param(Int, :id))\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.returning","page":"API Reference","title":"SQLSketch.Core.returning","text":"returning(q::Query, OutT::Type, fields...)::Returning{OutT}\n\nAdd a RETURNING clause to a DML operation.\n\nThis is a shape-changing operation that transforms a DML query into a query that returns typed results from the affected rows.\n\nArguments\n\nq: DML query (InsertValues, UpdateSet, UpdateWhere, DeleteFrom, or DeleteWhere)\nOutT: Output type (typically NamedTuple or a struct type)\nfields...: Expressions for fields to return\n\nReturns\n\nA Returning{OutT} query node\n\nExample\n\n# Basic RETURNING with placeholder syntax\nq = insert_into(:users, [:email]) |>\n    values([[literal(\"test@example.com\")]]) |>\n    returning(NamedTuple, p_.id, p_.email)\n\n# RETURNING with explicit column references\nq = update(:users) |>\n    set(:status => literal(\"active\")) |>\n    where(col(:users, :id) == param(Int, :id)) |>\n    returning(NamedTuple, col(:users, :id), col(:users, :status))\n\n\n\n\n\nreturning(OutT::Type, fields...)\n\nCurried version of returning for pipeline composition.\n\nExample\n\nq = insert_into(:users, [:email]) |>\n    values([[literal(\"test@example.com\")]]) |>\n    returning(NamedTuple, p_.id, p_.email)\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.create_table","page":"API Reference","title":"SQLSketch.Core.create_table","text":"create_table(table::Symbol; if_not_exists::Bool=false, temporary::Bool=false) -> CreateTable\n\nCreate a CREATE TABLE statement.\n\nExample\n\ncreate_table(:users)\ncreate_table(:users; if_not_exists = true)\ncreate_table(:temp_data; temporary = true)\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.alter_table","page":"API Reference","title":"SQLSketch.Core.alter_table","text":"alter_table(table::Symbol) -> AlterTable\n\nCreate an ALTER TABLE statement.\n\nExample\n\nalter_table(:users) |>\nadd_alter_column(:age, :integer)\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.drop_table","page":"API Reference","title":"SQLSketch.Core.drop_table","text":"drop_table(table::Symbol; if_exists::Bool=false, cascade::Bool=false) -> DropTable\n\nCreate a DROP TABLE statement.\n\nExample\n\ndrop_table(:users)\ndrop_table(:users; if_exists = true)\ndrop_table(:users; cascade = true)\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.add_column","page":"API Reference","title":"SQLSketch.Core.add_column","text":"add_column(ct::CreateTable, name::Symbol, type::ColumnType;\n           primary_key::Bool=false, nullable::Bool=true, unique::Bool=false,\n           default::Union{SQLExpr, Nothing}=nothing,\n           references::Union{Tuple{Symbol, Symbol}, Nothing}=nothing,\n           check::Union{SQLExpr, Nothing}=nothing,\n           auto_increment::Bool=false,\n           generated::Union{SQLExpr, Nothing}=nothing,\n           stored::Bool=true,\n           collation::Union{Symbol, Nothing}=nothing,\n           on_update::Union{SQLExpr, Nothing}=nothing,\n           comment::Union{String, Nothing}=nothing,\n           identity::Bool=false,\n           identity_always::Bool=false,\n           identity_start::Union{Int, Nothing}=nothing,\n           identity_increment::Union{Int, Nothing}=nothing) -> CreateTable\n\nAdd a column to a CREATE TABLE statement.\n\nKeyword Arguments\n\nprimary_key::Bool – Mark as PRIMARY KEY\nnullable::Bool – Allow NULL values (default true)\nunique::Bool – Add UNIQUE constraint\ndefault::Union{SQLExpr, Nothing} – Default value expression\nreferences::Union{Tuple{Symbol, Symbol}, Nothing} – Foreign key reference (table, column)\ncheck::Union{SQLExpr, Nothing} – Column-level CHECK constraint\nauto_increment::Bool – AUTO_INCREMENT / SERIAL (dialect-specific)\ngenerated::Union{SQLExpr, Nothing} – GENERATED column expression\nstored::Bool – STORED (true) or VIRTUAL (false) for GENERATED columns\ncollation::Union{Symbol, Nothing} – COLLATE clause for string columns\non_update::Union{SQLExpr, Nothing} – ON UPDATE clause (MySQL)\ncomment::Union{String, Nothing} – Column comment\nidentity::Bool – IDENTITY column (PostgreSQL)\nidentity_always::Bool – ALWAYS (true) or BY DEFAULT (false) for IDENTITY\nidentity_start::Union{Int, Nothing} – Starting value for IDENTITY\nidentity_increment::Union{Int, Nothing} – Increment value for IDENTITY\n\nExample\n\ncreate_table(:users) |>\nadd_column(:id, :integer; primary_key = true, auto_increment = true) |>\nadd_column(:email, :text; nullable = false, unique = true, collation = :nocase) |>\nadd_column(:age, :integer; check = col(:users, :age) >= literal(0)) |>\nadd_column(:created_at, :timestamp; default = literal(:current_timestamp))\n\n\n\n\n\nadd_column(name::Symbol, type::ColumnType; kwargs...) -> Function\n\nCurried version of add_column for pipeline composition.\n\nExample\n\ncreate_table(:users) |>\nadd_column(:id, :integer; primary_key = true, auto_increment = true) |>\nadd_column(:email, :text; nullable = false, collation = :nocase)\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.create_index","page":"API Reference","title":"SQLSketch.Core.create_index","text":"create_index(name::Symbol, table::Symbol, columns::Vector{Symbol};\n             unique::Bool=false, if_not_exists::Bool=false,\n             where::Union{SQLExpr, Nothing}=nothing,\n             expr::Union{Vector{SQLExpr}, Nothing}=nothing,\n             method::Union{Symbol, Nothing}=nothing) -> CreateIndex\n\nCreate a CREATE INDEX statement.\n\nKeyword Arguments\n\nunique::Bool – Create a unique index\nif_not_exists::Bool – Include IF NOT EXISTS clause\nwhere::Union{SQLExpr, Nothing} – Partial index condition\nexpr::Union{Vector{SQLExpr}, Nothing} – Expression index (mutually exclusive with columns)\nmethod::Union{Symbol, Nothing} – Index method (:btree, :hash, :gin, :gist, :brin, :spgist) - PostgreSQL only\n\nExample\n\n# Column index\ncreate_index(:idx_users_email, :users, [:email])\ncreate_index(:idx_users_email, :users, [:email]; unique = true)\n\n# Partial index\ncreate_index(:idx_active_users, :users, [:id];\n             where = col(:users, :active) == literal(true))\n\n# Expression index\ncreate_index(:idx_users_lower_email, :users, Symbol[];\n             expr = [func(:lower, [col(:users, :email)])])\n\n# Index with method (PostgreSQL)\ncreate_index(:idx_users_tags, :users, [:tags]; method = :gin)\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.drop_index","page":"API Reference","title":"SQLSketch.Core.drop_index","text":"drop_index(name::Symbol; if_exists::Bool=false) -> DropIndex\n\nCreate a DROP INDEX statement.\n\nExample\n\ndrop_index(:idx_users_email)\ndrop_index(:idx_users_email; if_exists = true)\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.col","page":"API Reference","title":"SQLSketch.Core.col","text":"col(table::Symbol, column::Symbol) -> ColRef\n\nConvenience constructor for column references.\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.literal","page":"API Reference","title":"SQLSketch.Core.literal","text":"literal(value::Any) -> Literal\n\nConvenience constructor for literal values. Accepts any Julia value to be embedded as a literal in SQL.\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.param","page":"API Reference","title":"SQLSketch.Core.param","text":"param(T::Type, name::Symbol) -> Param\n\nConvenience constructor for bound parameters.\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Extras.p_","page":"API Reference","title":"SQLSketch.Extras.p_","text":"const p_ = Placeholder()\n\nGlobal placeholder constant for convenient field access.\n\nNote: Uses p_ instead of _ because Julia reserves underscore-only identifiers for write-only variables.\n\nUsage\n\nfrom(:users) |>\nwhere(p_.age > literal(18)) |>\nselect(NamedTuple, p_.id, p_.email)\n\nInternally, p_.column creates a PlaceholderField(:column) which is resolved to ColRef(table, :column) during query compilation.\n\n\n\n\n\n","category":"constant"},{"location":"api/#SQLSketch.Core.cast","page":"API Reference","title":"SQLSketch.Core.cast","text":"cast(expr::SQLExpr, target_type::Symbol) -> Cast\n\nConvenience constructor for type casting.\n\nExample\n\ncast(col(:users, :age), :TEXT)\n# → CAST(users.age AS TEXT)\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.subquery","page":"API Reference","title":"SQLSketch.Core.subquery","text":"subquery(query) -> Subquery\n\nConvenience constructor for subquery expressions.\n\nExample\n\nsq = subquery(from(:orders) |> select(NamedTuple, col(:orders, :user_id)))\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.fetch_all","page":"API Reference","title":"SQLSketch.Core.fetch_all","text":"fetch_all(conn::PostgreSQLConnection,\n          dialect::Dialect,\n          registry::CodecRegistry,\n          query::Query{T},\n          params::NamedTuple = NamedTuple();\n          use_prepared::Bool = true) -> Vector{T}\n\nPostgreSQL-optimized version of fetch_all using DecodePlan and Prepared Statement Caching.\n\nThis specialization automatically uses two key optimizations:\n\nDecodePlan Optimization: Pre-resolves column types and codecs\n15-19% faster execution\n24-25% memory reduction\n26% fewer allocations\nPrepared Statement Caching: Caches compiled SQL statements\n10-20% faster for repeated queries\nReduced PostgreSQL server load\nLRU eviction policy (default: 100 statements)\n\nCombined, these optimizations provide 25-35% performance improvement.\n\nPerformance (measured with DecodePlan only)\n\nSimple SELECT (500 rows): 18.95% faster, 24.83% less memory\nJOIN Query (1667 rows): 17.1% faster, 23.95% less memory\nORDER BY + LIMIT (10 rows): 11.34% faster, 25.17% less memory\n\nExample\n\nusing SQLSketch\n\nconn = connect(PostgreSQLDriver(), \"postgresql://localhost/mydb\")\ndialect = PostgreSQLDialect()\nregistry = PostgreSQLCodecRegistry()\n\nq = from(:users) |> select(NamedTuple, col(:users, :id), col(:users, :name))\n\n# Automatically uses both DecodePlan and Prepared Statement Caching\nusers = fetch_all(conn, dialect, registry, q)\n\n# Disable prepared statements if needed\nusers = fetch_all(conn, dialect, registry, q; use_prepared = false)\n\nImplementation\n\nThis function:\n\nCompiles the query to SQL\nChecks prepared statement cache (if enabled)\nPrepares statement on cache miss\nBinds parameters\nExecutes the query (prepared or direct)\nCreates a DecodePlan (pre-resolves column types and codecs)\nDecodes all rows using the optimized path\n\nSee prepare_decode_plan and decode_rows for DecodePlan implementation.\n\n\n\n\n\nfetch_all(conn::PostgreSQLConnection,\n          dialect::Dialect,\n          registry::CodecRegistry,\n          query::Query{T},\n          params::NamedTuple = NamedTuple();\n          use_prepared::Bool = true) -> Vector{T}\n\nPostgreSQL-optimized fetch_all for user-defined struct types.\n\nUses the same columnar-via-conversion strategy as the NamedTuple version, providing 5-8x speedup over direct LibPQ row × col access.\n\nPerformance\n\nSame performance characteristics as NamedTuple version:\n\n5.6-8.3x faster than direct LibPQ access\n40-155% overhead vs. raw LibPQ (vs. 1,000%+ before)\n86-87% memory reduction\n\nExample\n\nstruct User\n    id::Int\n    name::String\n    email::String\nend\n\nq = from(:users) |> select(User, col(:users, :id), col(:users, :name), col(:users, :email))\nusers = fetch_all(conn, dialect, registry, q)\n# → Vector{User} (fast!)\n\n\n\n\n\nfetch_all(conn::Connection, dialect::Dialect, registry::CodecRegistry,\n          query::Query{T}, params::NamedTuple = NamedTuple();\n          use_prepared::Bool = true) -> Vector{T}\n\nExecute a query and fetch all rows.\n\nAutomatically uses prepared statements with caching if the driver supports them. Prepared statements are cached to eliminate redundant parsing/planning overhead.\n\nArguments\n\nconn: Database connection\ndialect: SQL dialect for compilation\nregistry: Codec registry for type conversion\nquery: Query AST to execute\nparams: Named parameters for the query (default: empty NamedTuple)\nuse_prepared: Whether to use prepared statements if available (default: true)\n\nReturns\n\nVector of results of type T (where T is the query's output type)\n\nExample\n\nq = from(:users) |>\n    where(col(:users, :age) > param(Int, :min_age)) |>\n    select(NamedTuple, col(:users, :id), col(:users, :name))\n\nresults = fetch_all(db, dialect, registry, q, (min_age = 25,))\n# → Vector{NamedTuple}\n# Automatically uses prepared statements with caching\n\n# Disable prepared statements for specific query\nresults = fetch_all(db, dialect, registry, q, (min_age = 25,); use_prepared = false)\n# → Uses direct SQL execution\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.fetch_one","page":"API Reference","title":"SQLSketch.Core.fetch_one","text":"fetch_one(conn::Connection, dialect::Dialect, registry::CodecRegistry,\n          query::Query{T}, params::NamedTuple = NamedTuple()) -> T\n\nExecute a query and fetch exactly one row.\n\nArguments\n\nconn: Database connection\ndialect: SQL dialect for compilation\nregistry: Codec registry for type conversion\nquery: Query AST to execute\nparams: Named parameters for the query (default: empty NamedTuple)\n\nReturns\n\nSingle result of type T\n\nErrors\n\nThrows an error if the query returns zero rows\nThrows an error if the query returns more than one row\n\nExample\n\nq = from(:users) |>\n    where(col(:users, :id) == param(Int, :id)) |>\n    select(NamedTuple, col(:users, :id), col(:users, :email))\n\nuser = fetch_one(db, dialect, registry, q, (id = 1,))\n# → NamedTuple (exactly one row)\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.fetch_maybe","page":"API Reference","title":"SQLSketch.Core.fetch_maybe","text":"fetch_maybe(conn::Connection, dialect::Dialect, registry::CodecRegistry,\n            query::Query{T}, params::NamedTuple = NamedTuple()) -> Union{T, Nothing}\n\nExecute a query and fetch zero or one row.\n\nArguments\n\nconn: Database connection\ndialect: SQL dialect for compilation\nregistry: Codec registry for type conversion\nquery: Query AST to execute\nparams: Named parameters for the query (default: empty NamedTuple)\n\nReturns\n\nSingle result of type T if exactly one row is returned\nNothing if zero rows are returned\n\nErrors\n\nThrows an error if the query returns more than one row\n\nExample\n\nq = from(:users) |>\n    where(col(:users, :email) == param(String, :email)) |>\n    select(NamedTuple, col(:users, :id), col(:users, :email))\n\nuser = fetch_maybe(db, dialect, registry, q, (email = \"test@example.com\",))\n# → NamedTuple or Nothing\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.execute","page":"API Reference","title":"SQLSketch.Core.execute","text":"execute(conn::Connection, dialect::Dialect, query::Query,\n        params::NamedTuple = NamedTuple()) -> ExecResult\n\nUnified API for executing DML statements (INSERT, UPDATE, DELETE) with side effects.\n\nThis is the recommended API for all DML execution. Dispatches internally to execute_dml.\n\nArguments\n\nconn: Database connection\ndialect: SQL dialect for compilation\nquery: DML query AST\nparams: Named parameters for the query (default: empty NamedTuple)\n\nReturns\n\nExecResult containing:\n\ncommand_type::Symbol: Type of command executed (:insert, :update, :delete)\nrowcount::Union{Int, Nothing}: Number of rows affected (currently Nothing)\n\nExample\n\n# INSERT\nq = insert_into(:users, [:name, :email]) |>\n    values([[literal(\"Alice\"), literal(\"alice@example.com\")]])\nresult = execute(conn, dialect, q)\n# -> ExecResult(:insert, nothing)\n\n# UPDATE\nq = update(:users) |>\n    set(:status => literal(\"inactive\")) |>\n    where(col(:users, :age) > literal(100))\nresult = execute(conn, dialect, q)\n# -> ExecResult(:update, nothing)\n\n# DELETE\nq = delete_from(:users) |>\n    where(col(:users, :status) == literal(\"deleted\"))\nresult = execute(conn, dialect, q)\n# -> ExecResult(:delete, nothing)\n\n\n\n\n\nexecute(conn::Connection, dialect::Dialect, ddl::DDLStatement) -> ExecResult\n\nUnified API for executing DDL statements (CREATE TABLE, DROP TABLE, etc.) with side effects.\n\nThis is the recommended API for all DDL execution. Dispatches internally to execute_ddl.\n\nArguments\n\nconn: Database connection\ndialect: SQL dialect for compilation\nddl: DDL statement AST\n\nReturns\n\nExecResult containing:\n\ncommand_type::Symbol: Type of command executed (:createtable, :droptable, etc.)\nrowcount::Union{Int, Nothing}: Always nothing for DDL\n\nExample\n\n# CREATE TABLE\nddl = create_table(:users) |>\n      add_column(:id, :integer; primary_key = true) |>\n      add_column(:name, :text; nullable = false)\nresult = execute(conn, dialect, ddl)\n# -> ExecResult(:create_table, nothing)\n\n# DROP TABLE\nddl = drop_table(:users; if_exists = true)\nresult = execute(conn, dialect, ddl)\n# -> ExecResult(:drop_table, nothing)\n\n# CREATE INDEX\nddl = create_index(:idx_users_email) |> on(:users, :email)\nresult = execute(conn, dialect, ddl)\n# -> ExecResult(:create_index, nothing)\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.ExecResult","page":"API Reference","title":"SQLSketch.Core.ExecResult","text":"ExecResult\n\nResult of executing a statement with side effects (DML/DDL).\n\nFields\n\ncommand_type::Symbol: Type of command executed (:insert, :update, :delete, :createtable, :droptable, :altertable, :createindex, :drop_index, :unknown)\nrowcount::Union{Int, Nothing}: Number of rows affected (Nothing if unknown or not applicable)\n\nExample\n\nresult = execute(conn, dialect, insert_query, params)\nprintln(result.command_type)  # :insert\nprintln(result.rowcount)      # Nothing (currently not implemented)\n\n\n\n\n\n","category":"type"},{"location":"api/#SQLSketch.Core.transaction","page":"API Reference","title":"SQLSketch.Core.transaction","text":"transaction(f::Function, conn::SQLiteConnection) -> result\n\nExecute a function within a SQLite transaction.\n\nUses BEGIN TRANSACTION / COMMIT / ROLLBACK commands.\n\nArguments\n\nf: Function to execute. Receives SQLiteTransaction handle as argument.\nconn: SQLite database connection\n\nReturns\n\nThe return value of the function f\n\nExample\n\nresult = transaction(db) do tx\n    execute(tx, \"INSERT INTO users (email) VALUES (?)\", [\"alice@example.com\"])\n    execute(tx, \"INSERT INTO orders (user_id, total) VALUES (?, ?)\", [1, 100.0])\n    return \"success\"\nend\n\nImplementation Details\n\nBEGIN TRANSACTION starts the transaction\nCOMMIT is executed if the function completes successfully\nROLLBACK is executed if an exception occurs\nThe transaction handle can be used with execute() and all query execution APIs\n\n\n\n\n\ntransaction(f::Function, conn::PostgreSQLConnection) -> result\n\nExecute a function within a PostgreSQL transaction.\n\nUses BEGIN / COMMIT / ROLLBACK commands.\n\nArguments\n\nf: Function to execute. Receives PostgreSQLTransaction handle as argument.\nconn: PostgreSQL database connection\n\nReturns\n\nThe return value of the function f\n\nExample\n\nresult = transaction(db) do tx\n    execute(tx, \"INSERT INTO users (email) VALUES ($1)\", [\"alice@example.com\"])\n    execute(tx, \"INSERT INTO orders (user_id, total) VALUES ($1, $2)\", [1, 100.0])\n    return \"success\"\nend\n\nImplementation Details\n\nBEGIN starts the transaction\nCOMMIT is executed if the function completes successfully\nROLLBACK is executed if an exception occurs\nThe transaction handle can be used with execute() and all query execution APIs\n\n\n\n\n\ntransaction(f::Function, conn::MySQLConnection; isolation_level=nothing)\n\nExecute a function within a transaction.\n\nArguments\n\nf: Function to execute (takes TransactionHandle as argument)\nconn: Database connection\nisolation_level: Optional isolation level (:readuncommitted, :readcommitted, :repeatable_read, :serializable)\n\nExample\n\ntransaction(db) do txn\n    execute_sql(txn, \"INSERT INTO users (email) VALUES (?)\", [\"alice@example.com\"])\n    execute_sql(txn, \"INSERT INTO logs (action) VALUES (?)\", [\"user_created\"])\nend\n\n\n\n\n\ntransaction(f::Function, conn::Connection) -> result\n\nExecute a function within a database transaction.\n\nThe transaction automatically commits if the function completes successfully, or rolls back if an exception is thrown.\n\nArguments\n\nf: Function to execute within the transaction. Receives transaction handle as argument.\nconn: Database connection\n\nReturns\n\nThe return value of the function f\n\nExample\n\n# Simple transaction\nresult = transaction(db) do tx\n    execute(tx, \"INSERT INTO users (email) VALUES (?)\", [\"alice@example.com\"])\n    execute(tx, \"INSERT INTO orders (user_id, total) VALUES (?, ?)\", [1, 100.0])\n    return \"success\"\nend\n# result == \"success\"\n\n# Transaction with query execution\nusers = transaction(db) do tx\n    q = from(:users) |>\n        where(col(:users, :active) == literal(true)) |>\n        select(NamedTuple, col(:users, :id), col(:users, :email))\n\n    fetch_all(tx, dialect, registry, q)\nend\n# users is Vector{NamedTuple}\n\n# Transaction rollback on exception\ntry\n    transaction(db) do tx\n        execute(tx, \"INSERT INTO users (email) VALUES (?)\", [\"alice@example.com\"])\n        error(\"Something went wrong!\")\n        # Transaction is automatically rolled back\n    end\ncatch e\n    println(\"Transaction rolled back: \", e)\nend\n\nErrors\n\nRethrows any exception that occurs within the function f after rolling back the transaction.\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.savepoint","page":"API Reference","title":"SQLSketch.Core.savepoint","text":"savepoint(f::Function, tx::SQLiteTransaction, name::Symbol) -> result\n\nCreate a savepoint within a SQLite transaction for nested transaction semantics.\n\nUses SAVEPOINT / RELEASE / ROLLBACK TO commands.\n\nArguments\n\nf: Function to execute within the savepoint. Receives transaction handle.\ntx: SQLite transaction handle\nname: Unique name for the savepoint\n\nReturns\n\nThe return value of the function f\n\nExample\n\ntransaction(db) do tx\n    execute_sql(tx, \"INSERT INTO users (email) VALUES (?)\", [\"alice@example.com\"])\n\n    savepoint(tx, :sp1) do sp\n        execute_sql(sp, \"INSERT INTO orders (user_id, total) VALUES (?, ?)\", [1, 100.0])\n        # Rolls back to sp1 if error occurs\n    end\nend\n\nImplementation Details\n\nSAVEPOINT creates a new savepoint on the transaction stack\nRELEASE removes the savepoint on success\nROLLBACK TO restores database state to the savepoint, then RELEASE removes it\nSavepoints can be nested\n\n\n\n\n\nsavepoint(f::Function, tx::PostgreSQLTransaction, name::Symbol) -> result\n\nCreate a savepoint within a PostgreSQL transaction.\n\nUses SAVEPOINT / RELEASE / ROLLBACK TO commands.\n\nArguments\n\nf: Function to execute within the savepoint\ntx: PostgreSQL transaction handle\nname: Unique name for the savepoint\n\nReturns\n\nThe return value of the function f\n\nExample\n\ntransaction(db) do tx\n    execute_sql(tx, \"INSERT INTO users (email) VALUES ($1)\", [\"alice@example.com\"])\n\n    savepoint(tx, :sp1) do sp\n        execute_sql(sp, \"INSERT INTO orders (user_id, total) VALUES ($1, $2)\", [1, 100.0])\n        # Rolls back to sp1 if error occurs\n    end\nend\n\nImplementation Details\n\nSAVEPOINT creates a new savepoint on the transaction stack\nRELEASE removes the savepoint on success\nROLLBACK TO restores database state to the savepoint\nSavepoints can be nested\n\n\n\n\n\nsavepoint(f::Function, conn::MySQLConnection, name::Symbol)\n\nExecute a function within a savepoint (nested transaction).\n\nArguments\n\nf: Function to execute\nconn: Database connection (or transaction handle)\nname: Savepoint name\n\nExample\n\ntransaction(db) do txn\n    execute_sql(txn, \"INSERT INTO users (email) VALUES (?)\", [\"alice@example.com\"])\n\n    savepoint(txn, :create_log) do sp\n        execute_sql(sp, \"INSERT INTO logs (action) VALUES (?)\", [\"user_created\"])\n        # This will be rolled back\n        error(\"Something went wrong!\")\n    end\n\n    # Transaction continues despite savepoint rollback\nend\n\n\n\n\n\nsavepoint(f::Function, tx::TransactionHandle, name::Symbol) -> result\n\nCreate a savepoint within a transaction for nested transaction semantics.\n\nSavepoints allow partial rollback: if an exception occurs within the savepoint, only changes made within that savepoint are rolled back. The outer transaction can still commit.\n\nArguments\n\nf: Function to execute within the savepoint. Receives transaction handle.\ntx: Transaction handle (from outer transaction() call)\nname: Unique name for the savepoint\n\nReturns\n\nThe return value of the function f\n\nExample\n\ntransaction(db) do tx\n    # This insert is in the outer transaction\n    execute(tx, \"INSERT INTO users (email) VALUES (?)\", [\"alice@example.com\"])\n\n    # Savepoint for risky operation\n    try\n        savepoint(tx, :risky_operation) do sp\n            execute(sp, \"INSERT INTO orders (user_id, total) VALUES (?, ?)\", [1, 100.0])\n            # Some risky operation that might fail\n            if some_condition\n                error(\"Risky operation failed!\")\n            end\n        end\n    catch e\n        # Orders insert was rolled back, but users insert will still commit\n        println(\"Savepoint rolled back: \", e)\n    end\n\n    # User insert still commits\nend\n\n# Multiple savepoints\ntransaction(db) do tx\n    execute(tx, \"INSERT INTO users (email) VALUES (?)\", [\"alice@example.com\"])\n\n    savepoint(tx, :sp1) do sp1\n        execute(sp1, \"INSERT INTO orders (user_id, total) VALUES (?, ?)\", [1, 100.0])\n\n        savepoint(sp1, :sp2) do sp2\n            execute(sp2, \"INSERT INTO order_items (order_id, sku) VALUES (?, ?)\",\n                    [1, \"ABC123\"])\n        end\n    end\nend\n\nErrors\n\nRethrows any exception that occurs within the function f after rolling back to the savepoint.\n\nNotes\n\nSavepoints can be nested\nSavepoint names must be unique within a transaction\nSQLite uses SAVEPOINT/RELEASE/ROLLBACK TO commands\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.sql","page":"API Reference","title":"SQLSketch.Core.sql","text":"sql(dialect::Dialect, query::Query) -> String\n\nGenerate SQL string from a query for inspection (without executing).\n\nArguments\n\ndialect: SQL dialect for compilation\nquery: Query AST to compile\n\nReturns\n\nSQL string (with parameter placeholders)\n\nExample\n\nq = from(:users) |>\n    where(col(:users, :age) > param(Int, :min_age)) |>\n    select(NamedTuple, col(:users, :name))\n\nsql_str = sql(dialect, q)\n# → \"SELECT `name` FROM `users` WHERE `age` > ?\"\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.compile","page":"API Reference","title":"SQLSketch.Core.compile","text":"compile(dialect::Dialect, query::Query) -> (sql::String, params::Vector{Symbol})\n\nCompile a Query AST into a SQL string and parameter list.\n\nArguments\n\ndialect: The SQL dialect to use for compilation\nquery: The query AST to compile\n\nReturns\n\nsql: The generated SQL string\nparams: A vector of parameter names in the order they appear in the SQL\n\nExample\n\nq = from(:users) |> where(col(:users, :id) == param(Int, :user_id))\nsql, params = compile(SQLiteDialect(), q)\n# sql    → \"SELECT * FROM `users` WHERE `users`.`id` = ?\"\n# params → [:user_id]\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.explain","page":"API Reference","title":"SQLSketch.Core.explain","text":"explain(conn::Connection, dialect::Dialect, query::Query) -> String\n\nExecute EXPLAIN on a query and return the query plan.\n\nArguments\n\nconn: Database connection\ndialect: SQL dialect for compilation\nquery: Query AST to explain\n\nReturns\n\nEXPLAIN output as a string\n\nExample\n\nq = from(:users) |>\n    where(col(:users, :age) > literal(25)) |>\n    select(NamedTuple, col(:users, :name))\n\nplan = explain(db, dialect, q)\n# → EXPLAIN output\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.list_tables","page":"API Reference","title":"SQLSketch.Core.list_tables","text":"list_tables(conn::SQLiteConnection) -> Vector{String}\n\nList all tables in the SQLite database.\n\nQueries the sqlite_master system table.\n\nArguments\n\nconn: Active SQLite connection\n\nReturns\n\nVector of table names (excluding SQLite internal tables like sqlite_sequence)\n\nExample\n\nconn = connect(SQLiteDriver(), \"mydb.sqlite\")\ntables = list_tables(conn)\n# → [\"users\", \"posts\", \"comments\"]\n\n\n\n\n\nlist_tables(conn::PostgreSQLConnection; schema::String=\"public\") -> Vector{String}\n\nList all tables in a PostgreSQL database schema.\n\nQueries the information_schema.tables catalog.\n\nArguments\n\nconn: Active PostgreSQL connection\nschema: Schema name (default: \"public\")\n\nReturns\n\nVector of table names in the specified schema\n\nExample\n\nconn = connect(PostgreSQLDriver(), \"postgresql://localhost/mydb\")\ntables = list_tables(conn)\n# → [\"users\", \"posts\", \"comments\"]\n\n# List tables in specific schema\ntables = list_tables(conn; schema = \"analytics\")\n\n\n\n\n\nlist_tables(conn::MySQLConnection; schema::Union{String,Nothing}=nothing) -> Vector{String}\n\nList all tables in the database or schema.\n\nArguments\n\nconn: Active connection\nschema: Optional schema name (default: current database)\n\nReturns\n\nVector of table names sorted alphabetically\n\nExample\n\n# List tables in current database\ntables = list_tables(db)\n# → [\"comments\", \"posts\", \"users\"]\n\n# List tables in specific database\ntables = list_tables(db; schema = \"mydb\")\n# → [\"orders\", \"products\"]\n\n\n\n\n\nlist_tables(conn::Connection) -> Vector{String}\n\nList all tables in the database.\n\nReturns a vector of table names as strings.\n\nArguments\n\nconn: Active database connection\n\nReturns\n\nVector of table names (strings)\n\nExample\n\nconn = connect(SQLiteDriver(), \"mydb.sqlite\")\ntables = list_tables(conn)\n# → [\"users\", \"posts\", \"comments\"]\n\nImplementation\n\nThis function must be implemented by each driver. The default implementation throws an error.\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.list_schemas","page":"API Reference","title":"SQLSketch.Core.list_schemas","text":"list_schemas(conn::SQLiteConnection) -> Vector{String}\n\nList schemas in SQLite.\n\nSQLite does not have schemas in the same sense as PostgreSQL. Returns a single default schema name for compatibility.\n\nArguments\n\nconn: Active SQLite connection\n\nReturns\n\nVector with single element [\"main\"]\n\nExample\n\nconn = connect(SQLiteDriver(), \"mydb.sqlite\")\nschemas = list_schemas(conn)\n# → [\"main\"]\n\n\n\n\n\nlist_schemas(conn::PostgreSQLConnection) -> Vector{String}\n\nList all schemas in a PostgreSQL database.\n\nQueries information_schema.schemata, excluding system schemas.\n\nArguments\n\nconn: Active PostgreSQL connection\n\nReturns\n\nVector of schema names (excluding pg* and informationschema)\n\nExample\n\nconn = connect(PostgreSQLDriver(), \"postgresql://localhost/mydb\")\nschemas = list_schemas(conn)\n# → [\"public\", \"myapp\", \"analytics\"]\n\n\n\n\n\nlist_schemas(conn::MySQLConnection) -> Vector{String}\n\nList all schemas (databases) accessible to the current user.\n\nExcludes system schemas (information_schema, mysql, performance_schema, sys).\n\nReturns\n\nVector of schema names sorted alphabetically\n\nExample\n\nschemas = list_schemas(db)\n# → [\"mydb\", \"test\", \"warehouse\"]\n\n\n\n\n\nlist_schemas(conn::Connection) -> Vector{String}\n\nList all schemas in the database.\n\nNote: This is primarily for PostgreSQL. SQLite does not have schemas, and MySQL uses \"databases\" instead of schemas.\n\nArguments\n\nconn: Active database connection\n\nReturns\n\nVector of schema names (strings)\n\nExample\n\nconn = connect(PostgreSQLDriver(), \"postgresql://localhost/mydb\")\nschemas = list_schemas(conn)\n# → [\"public\", \"myapp\", \"analytics\"]\n\nImplementation\n\nThis function must be implemented by each driver. Drivers for databases without schema support (e.g., SQLite) should return an empty vector or a single default schema name.\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Core.describe_table","page":"API Reference","title":"SQLSketch.Core.describe_table","text":"describe_table(conn::SQLiteConnection, table::Symbol) -> Vector{ColumnInfo}\n\nDescribe the structure of a SQLite table.\n\nUses PRAGMA table_info to get column information.\n\nArguments\n\nconn: Active SQLite connection\ntable: Table name as a symbol\n\nReturns\n\nVector of ColumnInfo structs describing each column\n\nExample\n\nconn = connect(SQLiteDriver(), \"mydb.sqlite\")\ncolumns = describe_table(conn, :users)\nfor col in columns\n    println(\"$(col.name): $(col.type)\")\nend\n\n\n\n\n\ndescribe_table(conn::PostgreSQLConnection, table::Symbol;\n               schema::String=\"public\") -> Vector{ColumnInfo}\n\nDescribe the structure of a PostgreSQL table.\n\nQueries information_schema.columns and information_schema.key_column_usage.\n\nArguments\n\nconn: Active PostgreSQL connection\ntable: Table name as a symbol\nschema: Schema name (default: \"public\")\n\nReturns\n\nVector of ColumnInfo structs describing each column\n\nExample\n\nconn = connect(PostgreSQLDriver(), \"postgresql://localhost/mydb\")\ncolumns = describe_table(conn, :users)\nfor col in columns\n    println(\"$(col.name): $(col.type)\")\nend\n\n\n\n\n\ndescribe_table(conn::MySQLConnection, table::Symbol;\n               schema::Union{String,Nothing}=nothing) -> Vector{ColumnInfo}\n\nGet column information for a table.\n\nArguments\n\nconn: Active connection\ntable: Table name as Symbol\nschema: Optional schema name (default: current database)\n\nReturns\n\nVector of ColumnInfo structs with column metadata\n\nExample\n\ncolumns = describe_table(db, :users)\nfor col in columns\n    println(\"$(col.name): $(col.type)\")\nend\n\n# Specific schema\ncolumns = describe_table(db, :orders; schema = \"sales\")\n\n\n\n\n\ndescribe_table(conn::Connection, table::Symbol) -> Vector{ColumnInfo}\n\nDescribe the structure of a table.\n\nReturns information about all columns in the specified table.\n\nArguments\n\nconn: Active database connection\ntable: Table name as a symbol\n\nReturns\n\nVector of ColumnInfo structs describing each column\n\nExample\n\nconn = connect(SQLiteDriver(), \"mydb.sqlite\")\ncolumns = describe_table(conn, :users)\nfor col in columns\n    println(\"$(col.name): $(col.type)\")\nend\n\nImplementation\n\nThis function must be implemented by each driver. The default implementation throws an error.\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Extras.apply_migrations","page":"API Reference","title":"SQLSketch.Extras.apply_migrations","text":"apply_migrations(conn::Connection, dialect::Dialect, migrations_dir::String) -> Vector{Migration}\n\nApply all pending migrations from a directory.\n\nDiscovers all migrations in the directory, identifies which have not been applied, and applies them in order (oldest first). Each migration runs in its own transaction.\n\nArguments\n\nconn: Database connection\ndialect: SQL dialect\nmigrations_dir: Path to directory containing migration files\n\nReturns\n\nVector of migrations that were applied (empty if all migrations were already applied)\n\nExample\n\napplied = apply_migrations(conn, dialect, \"db/migrations\")\nprintln(\"Applied $(length(applied)) migrations\")\n\nErrors\n\nThrows error if migration directory doesn't exist\nThrows error if any migration fails (already-applied migrations are not rolled back)\nThrows error if applied migration checksum doesn't match file checksum (modification detected)\n\n\n\n\n\n","category":"function"},{"location":"api/#SQLSketch.Extras.migration_status","page":"API Reference","title":"SQLSketch.Extras.migration_status","text":"migration_status(conn::Connection, dialect::Dialect, migrations_dir::String) -> Vector{MigrationStatus}\n\nGet the status of all migrations (applied and pending).\n\nArguments\n\nconn: Database connection\ndialect: SQL dialect\nmigrations_dir: Path to directory containing migration files\n\nReturns\n\nVector of MigrationStatus structs, sorted by version (oldest first)\n\nExample\n\nstatus = migration_status(conn, dialect, \"db/migrations\")\nfor s in status\n    applied_str = s.applied ? \"✓\" : \"✗\"\n    println(\"$applied_str $(s.migration.version) $(s.migration.name)\")\nend\n\n\n\n\n\n","category":"function"},{"location":"getting-started/#Getting-Started-with-SQLSketch.jl","page":"Getting Started","title":"Getting Started with SQLSketch.jl","text":"⚠️ Note: This is a toy project for learning purposes, not intended for production use.\n\nSQLSketch.jl is a type-safe, composable SQL query builder for Julia. It provides a fluent API for constructing SQL queries that are checked at compile time while remaining transparent and inspectable.","category":"section"},{"location":"getting-started/#Installation","page":"Getting Started","title":"Installation","text":"using Pkg\nPkg.add(url=\"https://github.com/daikichiba9511/SQLSketch.jl\")","category":"section"},{"location":"getting-started/#Database-Setup","page":"Getting Started","title":"Database Setup","text":"","category":"section"},{"location":"getting-started/#PostgreSQL-(Primary-Target)","page":"Getting Started","title":"PostgreSQL (Primary Target)","text":"SQLSketch is designed with PostgreSQL as the primary target database. PostgreSQL offers rich native types (UUID, JSONB, ARRAY, TIMESTAMP WITH TIME ZONE) and advanced SQL features.\n\nInstall PostgreSQL driver:\n\nPkg.add(\"LibPQ\")\n\nConnect to PostgreSQL:\n\nusing SQLSketch\nusing SQLSketch.Drivers: PostgreSQLDriver\n\n# Create driver with connection string\ndriver = PostgreSQLDriver(\"host=localhost dbname=mydb user=myuser password=mypass\")\n\n# Or use environment variables\ndriver = PostgreSQLDriver(ENV[\"DATABASE_URL\"])","category":"section"},{"location":"getting-started/#SQLite-(Development/Testing)","page":"Getting Started","title":"SQLite (Development/Testing)","text":"SQLite is supported for fast local development and testing, but applications should target PostgreSQL for production.\n\nInstall SQLite driver:\n\nPkg.add(\"SQLite\")\n\nConnect to SQLite:\n\nusing SQLSketch\nusing SQLSketch.Drivers: SQLiteDriver\n\n# In-memory database\ndriver = SQLiteDriver(\":memory:\")\n\n# Or file-based\ndriver = SQLiteDriver(\"dev.db\")","category":"section"},{"location":"getting-started/#Your-First-Query","page":"Getting Started","title":"Your First Query","text":"","category":"section"},{"location":"getting-started/#Basic-SELECT","page":"Getting Started","title":"Basic SELECT","text":"using SQLSketch\n\n# Build a query\nq = from(:users) |>\n    where(col(:users, :active) == literal(true)) |>\n    select(NamedTuple, col(:users, :id), col(:users, :email))\n\n# Inspect generated SQL\nprintln(sql(q, PostgreSQLDialect()))\n# SELECT \"users\".\"id\", \"users\".\"email\" FROM \"users\" WHERE \"users\".\"active\" = $1\n\n# Execute query\nresults = fetch_all(driver, q)\n# Vector{NamedTuple{(:id, :email), Tuple{Int64, String}}}\n\nfor row in results\n    println(\"$(row.id): $(row.email)\")\nend","category":"section"},{"location":"getting-started/#Type-Safe-Structs","page":"Getting Started","title":"Type-Safe Structs","text":"Map query results directly to structs:\n\nstruct User\n    id::Int64\n    email::String\n    created_at::DateTime\nend\n\nq = from(:users) |>\n    select(User,\n           col(:users, :id),\n           col(:users, :email),\n           col(:users, :created_at))\n\nusers = fetch_all(driver, q)\n# Vector{User}","category":"section"},{"location":"getting-started/#Parameterized-Queries","page":"Getting Started","title":"Parameterized Queries","text":"Use placeholders for safe parameter binding:\n\n# Define parameter\nuser_id = p_(:user_id, Int64)\n\nq = from(:users) |>\n    where(col(:users, :id) == user_id) |>\n    select(User, col(:users, :id), col(:users, :email), col(:users, :created_at))\n\n# Execute with parameter values\nuser = fetch_one(driver, q, user_id => 42)\n# User(42, \"user@example.com\", DateTime(...))","category":"section"},{"location":"getting-started/#Core-Concepts","page":"Getting Started","title":"Core Concepts","text":"","category":"section"},{"location":"getting-started/#Execute-vs-Fetch:-Understanding-Query-Execution","page":"Getting Started","title":"Execute vs Fetch: Understanding Query Execution","text":"SQLSketch separates side-effecting operations from data retrieval operations.","category":"section"},{"location":"getting-started/#Use-execute-for-Side-Effects-(No-Data-Returned)","page":"Getting Started","title":"Use execute for Side Effects (No Data Returned)","text":"When you want to modify data or change schema without retrieving results:\n\n# INSERT without RETURNING\nq = insert_into(:users, [:email, :name]) |>\n    values([literal(\"alice@example.com\"), literal(\"Alice\")])\n\nrows_affected = execute(driver, q)\n# → 1 (number of rows inserted)\n\n# UPDATE\nq = update(:users) |>\n    set(:active, literal(false)) |>\n    where(col(:users, :last_login) < literal(DateTime(2024, 1, 1)))\n\nrows_affected = execute(driver, q)\n# → 42 (number of rows updated)\n\n# CREATE TABLE\nq = create_table(:posts) |>\n    add_column(:id, :integer) |>\n    add_column(:title, :text) |>\n    primary_key(:id)\n\nexecute(driver, q)\n# → 0 (DDL returns 0)\n\nKey points:\n\nReturns Int64 (number of affected rows for DML, 0 for DDL)\nDoes not decode or return data rows\nUse for: INSERT, UPDATE, DELETE (without RETURNING), CREATE TABLE, DROP TABLE, etc.","category":"section"},{"location":"getting-started/#Use-fetch_*-for-Data-Retrieval","page":"Getting Started","title":"Use fetch_* for Data Retrieval","text":"When you want to retrieve data from the database:\n\n# SELECT query\nq = from(:users) |>\n    where(col(:users, :active) == literal(true)) |>\n    select(NamedTuple, col(:users, :id), col(:users, :email))\n\nusers = fetch_all(driver, q)\n# → Vector{NamedTuple{(:id, :email), ...}}\n\n# INSERT with RETURNING\nq = insert_into(:users, [:email, :name]) |>\n    values([literal(\"bob@example.com\"), literal(\"Bob\")]) |>\n    returning(col(:users, :id))\n\nuser_id = fetch_one(driver, q, Int64)\n# → 42 (the new user's ID)\n\n# Fetch optional result\nq = from(:users) |>\n    where(col(:users, :id) == literal(999)) |>\n    select(User, col(:users, :id), col(:users, :email), col(:users, :created_at))\n\nuser = fetch_maybe(driver, q)\n# → nothing (if no user found) or User(...) (if found)\n\nKey points:\n\nfetch_all(conn, query) → Vector{T} (all rows, row-based)\nfetch_all_columnar(conn, query) → NamedTuple of Vectors (all rows, columnar - 8-10x faster)\nfetch_all_columnar(conn, query, ColumnarType) → ColumnarType (type-safe columnar)\nfetch_one(conn, query) → T (exactly one row, error if 0 or >1)\nfetch_maybe(conn, query) → Union{T, Nothing} (optional result)\nUse for: SELECT, INSERT/UPDATE/DELETE with RETURNING\n\nWhy this separation?\n\nIntent clarity: The function name tells you whether to expect data back\nType safety: fetch_* requires an explicit result type\nPerformance: execute skips unnecessary row decoding\nError prevention: Using the wrong function makes the mistake obvious","category":"section"},{"location":"getting-started/#Query-Building-Styles","page":"Getting Started","title":"Query Building Styles","text":"SQLSketch provides flexible query building. Here are three approaches:","category":"section"},{"location":"getting-started/#1.-Pipeline-Style-(Recommended)","page":"Getting Started","title":"1. Pipeline Style (Recommended)","text":"The pipeline style uses |> to chain operations, mirroring SQL's logical evaluation order:\n\nq = from(:users) |>\n    where(col(:users, :active) == literal(true)) |>\n    order_by(col(:users, :created_at); desc=true) |>\n    limit(10) |>\n    select(User, col(:users, :id), col(:users, :email))\n\nAdvantages:\n\nReads naturally from top to bottom (FROM → WHERE → ORDER BY → LIMIT → SELECT)\nMatches SQL's logical evaluation order\nEasy to add/remove operations\nMost readable for complex queries","category":"section"},{"location":"getting-started/#2.-Nested-Style","page":"Getting Started","title":"2. Nested Style","text":"Functions can be nested, but this reads inside-out:\n\nq = select(\n    limit(\n        order_by(\n            where(\n                from(:users),\n                col(:users, :active) == literal(true)\n            ),\n            col(:users, :created_at); desc=true\n        ),\n        10\n    ),\n    User,\n    col(:users, :id),\n    col(:users, :email)\n)\n\nDrawbacks:\n\nReads from innermost to outermost (reverse order)\nHard to scan visually\nDifficult to modify","category":"section"},{"location":"getting-started/#3.-Step-by-Step-Style","page":"Getting Started","title":"3. Step-by-Step Style","text":"Queries can be built incrementally by assigning intermediate results:\n\nq1 = from(:users)\nq2 = where(q1, col(:users, :active) == literal(true))\nq3 = order_by(q2, col(:users, :created_at); desc=true)\nq4 = limit(q3, 10)\nq5 = select(q4, User, col(:users, :id), col(:users, :email))\n\nUse cases:\n\nConditional query building\nDebugging intermediate steps\nWhen clarity is more important than conciseness\n\nAll three styles generate identical SQL:\n\nSELECT \"users\".\"id\", \"users\".\"email\"\nFROM \"users\"\nWHERE \"users\".\"active\" = $1\nORDER BY \"users\".\"created_at\" DESC\nLIMIT $2\n\nRecommendation: Use the pipeline style for most cases. Use step-by-step when you need conditional logic or debugging.","category":"section"},{"location":"getting-started/#Shape-Preserving-vs-Shape-Changing","page":"Getting Started","title":"Shape-Preserving vs Shape-Changing","text":"Shape-Preserving: Operations that don't change the output type\nfrom, where, join, order_by, limit, offset, distinct, group_by, having\nShape-Changing: Only select changes the output type\nMust specify output type: select(NamedTuple, ...) or select(User, ...)","category":"section"},{"location":"getting-started/#SQL-Transparency","page":"Getting Started","title":"SQL Transparency","text":"All queries are inspectable before execution:\n\nq = from(:users) |> where(col(:users, :active) == literal(true))\n\n# View generated SQL\nprintln(sql(q, PostgreSQLDialect()))\n\n# Get SQL with parameter positions\ncompiled = compile(PostgreSQLDialect(), q)\nprintln(compiled.sql)\nprintln(compiled.param_order)\n\n# View EXPLAIN plan\nprintln(explain(q, PostgreSQLDialect()))","category":"section"},{"location":"getting-started/#Common-Patterns","page":"Getting Started","title":"Common Patterns","text":"","category":"section"},{"location":"getting-started/#Joins","page":"Getting Started","title":"Joins","text":"q = from(:users) |>\n    join(:posts, col(:posts, :user_id) == col(:users, :id); kind=:left) |>\n    select(NamedTuple,\n           col(:users, :email),\n           col(:posts, :title))","category":"section"},{"location":"getting-started/#Ordering-and-Limiting","page":"Getting Started","title":"Ordering and Limiting","text":"q = from(:users) |>\n    order_by(col(:users, :created_at); desc=true) |>\n    limit(10)","category":"section"},{"location":"getting-started/#Aggregation","page":"Getting Started","title":"Aggregation","text":"q = from(:orders) |>\n    group_by(col(:orders, :user_id)) |>\n    select(NamedTuple,\n           col(:orders, :user_id),\n           count_star())","category":"section"},{"location":"getting-started/#Subqueries","page":"Getting Started","title":"Subqueries","text":"subq = from(:orders) |>\n       select(NamedTuple, col(:orders, :user_id))\n\nq = from(:users) |>\n    where(col(:users, :id) |> in_(subquery(subq)))","category":"section"},{"location":"getting-started/#DML-Operations","page":"Getting Started","title":"DML Operations","text":"","category":"section"},{"location":"getting-started/#INSERT","page":"Getting Started","title":"INSERT","text":"q = insert_into(:users, [:email, :active]) |>\n    values([literal(\"new@example.com\"), literal(true)])\n\nexecute(driver, q)","category":"section"},{"location":"getting-started/#UPDATE","page":"Getting Started","title":"UPDATE","text":"q = update(:users) |>\n    set_(:email, literal(\"updated@example.com\")) |>\n    where(col(:users, :id) == literal(1))\n\nexecute(driver, q)","category":"section"},{"location":"getting-started/#DELETE","page":"Getting Started","title":"DELETE","text":"q = delete_from(:users) |>\n    where(col(:users, :active) == literal(false))\n\nexecute(driver, q)","category":"section"},{"location":"getting-started/#RETURNING-(PostgreSQL)","page":"Getting Started","title":"RETURNING (PostgreSQL)","text":"q = insert_into(:users, [:email, :active]) |>\n    values([literal(\"new@example.com\"), literal(true)]) |>\n    returning(col(:users, :id))\n\nnew_id = fetch_one(driver, q)","category":"section"},{"location":"getting-started/#Transactions","page":"Getting Started","title":"Transactions","text":"result = transaction(driver) do tx\n    # Multiple operations in transaction\n    execute(tx, insert_query)\n    execute(tx, update_query)\n\n    # Fetch within transaction\n    user = fetch_one(tx, select_query)\n\n    # Return value from transaction\n    user.id\nend\n\n# Automatically commits on success, rolls back on error","category":"section"},{"location":"getting-started/#Savepoints-(Nested-Transactions)","page":"Getting Started","title":"Savepoints (Nested Transactions)","text":"transaction(driver) do tx\n    execute(tx, query1)\n\n    savepoint(tx, :sp1) do sp\n        execute(sp, query2)\n        # Rolls back to sp1 on error\n    end\n\n    execute(tx, query3)\nend","category":"section"},{"location":"getting-started/#PostgreSQL-Specific-Features","page":"Getting Started","title":"PostgreSQL-Specific Features","text":"","category":"section"},{"location":"getting-started/#UUID","page":"Getting Started","title":"UUID","text":"using UUIDs\n\nstruct User\n    id::UUID\n    email::String\nend\n\nq = from(:users) |>\n    where(col(:users, :id) == literal(uuid4())) |>\n    select(User, col(:users, :id), col(:users, :email))","category":"section"},{"location":"getting-started/#JSONB","page":"Getting Started","title":"JSONB","text":"# Store JSON data\nmetadata = Dict(\"tags\" => [\"admin\", \"verified\"], \"score\" => 100)\n\nq = insert_into(:users, [:email, :metadata]) |>\n    values([literal(\"user@example.com\"), literal(metadata)])\n\nexecute(driver, q)","category":"section"},{"location":"getting-started/#Arrays","page":"Getting Started","title":"Arrays","text":"# Query with array literal\ntags = [\"julia\", \"database\"]\n\nq = from(:posts) |>\n    where(col(:posts, :tags) == literal(tags))","category":"section"},{"location":"getting-started/#Next-Steps","page":"Getting Started","title":"Next Steps","text":"API Reference - Complete API documentation\nTutorial - Step-by-step learning path\nDesign Philosophy - Understanding SQLSketch's architecture","category":"section"},{"location":"getting-started/#Getting-Help","page":"Getting Started","title":"Getting Help","text":"Check the API Reference for function documentation\nReport issues at GitHub Issues","category":"section"},{"location":"performance/#Performance-Guide","page":"Performance Guide","title":"Performance Guide","text":"SQLSketch provides two result formats optimized for different use cases:\n\nRow-based API (fetch_all) - Optimized for CRUD operations\nColumnar API (fetch_all_columnar) - Optimized for analytics\n\n","category":"section"},{"location":"performance/#Quick-Comparison","page":"Performance Guide","title":"Quick Comparison","text":"API Format Performance Best Use Case\nfetch_all Vector{T} Fast (40-155% overhead) CRUD, small datasets\nfetch_all_columnar NamedTuple of Vectors Fastest (4-12% overhead) Analytics, large datasets\nfetch_all_columnar(_, _, _, ColumnarType) Custom struct Fastest + type-safe Production analytics\n\n","category":"section"},{"location":"performance/#Benchmark-Results-(PostgreSQL)","page":"Performance Guide","title":"Benchmark Results (PostgreSQL)","text":"","category":"section"},{"location":"performance/#Simple-SELECT-(500-rows)","page":"Performance Guide","title":"Simple SELECT (500 rows)","text":"Method Time Memory Allocations Overhead\nRaw LibPQ 234 μs 4.27 KiB 120 0% (baseline)\nfetch_all 327 μs 96.83 KiB 2,191 40% ✅\nfetch_all_columnar 252 μs 6.83 KiB 188 12% ✅\n\nSpeedup: Columnar is 1.3x faster than row-based","category":"section"},{"location":"performance/#JOIN-Query-(1667-rows)","page":"Performance Guide","title":"JOIN Query (1667 rows)","text":"Method Time Memory Allocations Overhead\nRaw LibPQ 997 μs 4.95 KiB 140 0% (baseline)\nfetch_all 2.530 ms 465 KiB 15,229 155% ✅\nfetch_all_columnar 1.055 ms 8.92 KiB 232 6% ✅\n\nSpeedup: Columnar is 2.4x faster than row-based\n\n","category":"section"},{"location":"performance/#Row-Based-API-(fetch_all)","page":"Performance Guide","title":"Row-Based API (fetch_all)","text":"","category":"section"},{"location":"performance/#Performance-Characteristics","page":"Performance Guide","title":"Performance Characteristics","text":"Overhead: 40-155% vs. raw LibPQ\nMemory: Moderate (allocates one NamedTuple/struct per row)\nSpeed: Fast for small-medium datasets","category":"section"},{"location":"performance/#When-to-Use","page":"Performance Guide","title":"When to Use","text":"✅ CRUD operations - Iterate over individual records\n\nusers = fetch_all(conn, dialect, registry, query)\nfor user in users\n    send_email(user.email, \"Welcome!\")\nend\n\n✅ Small to medium datasets (<10,000 rows)\n\n# Fast enough for typical web app queries\nrecent_orders = fetch_all(conn, dialect, registry, orders_query)\n\n✅ Object mapping\n\nstruct User\n    id::Int\n    email::String\nend\n\nusers = fetch_all(conn, dialect, registry, query)\n# → Vector{User}","category":"section"},{"location":"performance/#Implementation-Details","page":"Performance Guide","title":"Implementation Details","text":"Under the hood, fetch_all uses columnar-via-conversion strategy:\n\nFetch data in bulk columnar format (LibPQ optimized)\nConvert to row-based format (Pure Julia, no LibPQ calls)\n\nThis achieves 5-8x speedup vs. naive row-by-row LibPQ access.\n\n","category":"section"},{"location":"performance/#Columnar-API-(fetch_all_columnar)","page":"Performance Guide","title":"Columnar API (fetch_all_columnar)","text":"","category":"section"},{"location":"performance/#Performance-Characteristics-2","page":"Performance Guide","title":"Performance Characteristics","text":"Overhead: 4-12% vs. raw LibPQ (near-optimal!)\nMemory: Minimal (bulk allocations)\nSpeed: Fastest possible (8-10x faster than row-based)","category":"section"},{"location":"performance/#When-to-Use-2","page":"Performance Guide","title":"When to Use","text":"✅ Analytics queries - Column-wise aggregations\n\nsales = fetch_all_columnar(conn, dialect, registry, sales_query)\ntotal_revenue = sum(sales.amount)\n\n✅ Large datasets (>1,000 rows)\n\n# 8-10x faster for large result sets\nmetrics = fetch_all_columnar(conn, dialect, registry, metrics_query)\n\n✅ DataFrame export\n\nusing DataFrames\n\ndata = fetch_all_columnar(conn, dialect, registry, query)\ndf = DataFrame(data)  # Zero-copy conversion!\nCSV.write(\"output.csv\", df)\n\n✅ Statistical operations\n\nusing Statistics\n\nmetrics = fetch_all_columnar(conn, dialect, registry, query)\nμ = mean(metrics.value)\nσ = std(metrics.value)","category":"section"},{"location":"performance/#Option-1:-NamedTuple-of-Vectors-(Flexible)","page":"Performance Guide","title":"Option 1: NamedTuple of Vectors (Flexible)","text":"result = fetch_all_columnar(conn, dialect, registry, query)\n# → (id = [1, 2, 3, ...], amount = [100.0, 200.0, ...])\n\ntotal = sum(result.amount)\n\nPros:\n\nNo extra struct definition needed\nDirect access to columns\nEasy DataFrame conversion\n\nCons:\n\nType is generic (less compile-time checking)","category":"section"},{"location":"performance/#Option-2:-Type-Safe-Columnar-Struct-(Recommended)","page":"Performance Guide","title":"Option 2: Type-Safe Columnar Struct (Recommended)","text":"# Define columnar struct (fields as Vectors)\nstruct SalesColumnar\n    id::Vector{Int}\n    amount::Vector{Float64}\n    product::Vector{String}\nend\n\n# Fetch with type safety\nresult = fetch_all_columnar(conn, dialect, registry, query, SalesColumnar)\n# → SalesColumnar([1, 2, 3, ...], [100.0, 200.0, ...], [\"A\", \"B\", ...])\n\ntotal = sum(result.amount)  # Type-safe!\n\nPros:\n\n✅ Type-safe (compiler checks field names and types)\n✅ Clear documentation (struct shows what data to expect)\n✅ Better IDE support\n\nCons:\n\nRequires struct definition\nSmall overhead (~12.8%) for conversion\n\n","category":"section"},{"location":"performance/#Performance-Optimization-History","page":"Performance Guide","title":"Performance Optimization History","text":"","category":"section"},{"location":"performance/#Initial-Implementation-(Before-Optimization)","page":"Performance Guide","title":"Initial Implementation (Before Optimization)","text":"Query Time Overhead\n500 rows 2.7 ms 1,073% ❌\n1667 rows 14.1 ms 1,316% ❌\n\nBottleneck: O(rows × cols) individual LibPQ accesses","category":"section"},{"location":"performance/#After-Columnar-via-Conversion-Optimization","page":"Performance Guide","title":"After Columnar-via-Conversion Optimization","text":"Query Time Overhead Improvement\n500 rows 327 μs 40% ✅ 8.3x faster\n1667 rows 2.5 ms 155% ✅ 5.6x faster\n\nKey insight: Use LibPQ's bulk columnar operations + Pure Julia conversion","category":"section"},{"location":"performance/#Why-It-Works","page":"Performance Guide","title":"Why It Works","text":"Old approach (slow):\n\n# O(rows × cols) LibPQ calls\nfor row in 1:nrows\n    for col in 1:ncols\n        value = result[row, col]  # Expensive C boundary crossing!\n    end\nend\n# 500 × 2 = 1,000 LibPQ calls\n\nNew approach (fast):\n\n# Step 1: Bulk columnar fetch (5-10 LibPQ calls total)\ncolumnar = LibPQ.columntable(result)\n\n# Step 2: Pure Julia conversion (no LibPQ calls)\nrows = _columnar_to_rows(columnar)\n\nResult: 1,000 calls → 5 calls = 200x fewer boundary crossings\n\n","category":"section"},{"location":"performance/#Choosing-the-Right-API","page":"Performance Guide","title":"Choosing the Right API","text":"","category":"section"},{"location":"performance/#Decision-Tree","page":"Performance Guide","title":"Decision Tree","text":"Is this an analytics query with >1,000 rows?\n├─ Yes → Use fetch_all_columnar (8-10x faster)\n│   └─ Production code? → Use type-safe struct version\n│   └─ Exploration? → Use NamedTuple version\n│\n└─ No → Use fetch_all (simpler API)\n    └─ CRUD / row-by-row iteration? → fetch_all\n    └─ Small aggregation? → Either works","category":"section"},{"location":"performance/#Real-World-Examples","page":"Performance Guide","title":"Real-World Examples","text":"","category":"section"},{"location":"performance/#Example-1:-Web-Application-(Use-fetch_all)","page":"Performance Guide","title":"Example 1: Web Application (Use fetch_all)","text":"# Fetch user profile (small result)\nuser = fetch_one(conn, dialect, registry, user_query)\n\n# Fetch recent orders (20-100 rows)\norders = fetch_all(conn, dialect, registry, orders_query)\nfor order in orders\n    display_order(order)\nend\n\nWhy: Small datasets, row-by-row iteration natural","category":"section"},{"location":"performance/#Example-2:-Analytics-Dashboard-(Use-fetch_all_columnar)","page":"Performance Guide","title":"Example 2: Analytics Dashboard (Use fetch_all_columnar)","text":"struct SalesMetrics\n    date::Vector{Date}\n    revenue::Vector{Float64}\n    orders::Vector{Int}\nend\n\n# Fetch 30 days of metrics (1000+ rows)\nmetrics = fetch_all_columnar(conn, dialect, registry, metrics_query, SalesMetrics)\n\n# Column-wise aggregations (extremely fast)\ntotal_revenue = sum(metrics.revenue)\ntotal_orders = sum(metrics.orders)\navg_order_value = total_revenue / total_orders\n\nWhy: Large dataset, column-wise operations, type-safe","category":"section"},{"location":"performance/#Example-3:-Data-Export-(Use-fetch_all_columnar)","page":"Performance Guide","title":"Example 3: Data Export (Use fetch_all_columnar)","text":"# Export large dataset to CSV (10,000+ rows)\ndata = fetch_all_columnar(conn, dialect, registry, export_query)\n\nusing DataFrames, CSV\ndf = DataFrame(data)\nCSV.write(\"export.csv\", df)\n\nWhy: Large dataset, DataFrame conversion, performance critical\n\n","category":"section"},{"location":"performance/#Summary","page":"Performance Guide","title":"Summary","text":"Scenario Recommended API Reasoning\nCRUD operations fetch_all Row-by-row iteration natural\nSmall results (<1K rows) fetch_all Overhead acceptable\nAnalytics (>1K rows) fetch_all_columnar 8-10x faster\nDataFrame export fetch_all_columnar Near zero-cost conversion\nProduction analytics fetch_all_columnar(_, _, _, Struct) Type-safe + fast\n\nBoth APIs are fast - choose based on your use case!\n\n","category":"section"},{"location":"performance/#Prepared-Statement-Caching-(MySQL,-PostgreSQL)","page":"Performance Guide","title":"Prepared Statement Caching (MySQL, PostgreSQL)","text":"SQLSketch automatically caches prepared statements to eliminate redundant SQL parsing and planning overhead.","category":"section"},{"location":"performance/#Performance-Impact","page":"Performance Guide","title":"Performance Impact","text":"MySQL: 10-20% faster for repeated queries\nPostgreSQL: 10-20% faster for repeated queries\nReduced database server load\nLower network overhead (binary protocol)","category":"section"},{"location":"performance/#How-It-Works","page":"Performance Guide","title":"How It Works","text":"# Prepared statements are automatically cached (LRU eviction)\nq = from(:users) |>\n    where(col(:users, :age) > param(Int, :min_age)) |>\n    select(NamedTuple, col(:users, :id), col(:users, :email))\n\n# First execution - cache miss, statement prepared and cached\nresult1 = fetch_all(conn, dialect, registry, q, (min_age=25,); use_prepared=true)\n\n# Second execution with different params - cache hit, reuses prepared statement\nresult2 = fetch_all(conn, dialect, registry, q, (min_age=30,); use_prepared=true)\n\n# Third execution with same query - still cache hit\nresult3 = fetch_all(conn, dialect, registry, q, (min_age=35,); use_prepared=true)","category":"section"},{"location":"performance/#Configuration","page":"Performance Guide","title":"Configuration","text":"MySQL:\n\n# Custom cache size (default: 100 statements)\nraw_conn = DBInterface.connect(MySQL.Connection, host, user, password; db=db)\nconn = MySQLConnection(raw_conn; cache_size=200, enable_cache=true)\n\n# Disable caching if needed\nconn = MySQLConnection(raw_conn; enable_cache=false)\n\nPostgreSQL:\n\n# Custom cache size\nraw_conn = LibPQ.Connection(connection_string)\nconn = PostgreSQLConnection(raw_conn; cache_size=200, enable_cache=true)","category":"section"},{"location":"performance/#When-to-Use-3","page":"Performance Guide","title":"When to Use","text":"✅ Repeated queries with different parameters\n\n# API endpoint that runs same query with different IDs\nfor user_id in user_ids\n    user = fetch_one(conn, dialect, registry, user_query, (id=user_id,); use_prepared=true)\n    process_user(user)\nend\n\n✅ High-throughput applications\n\nWeb APIs with standardized queries\nBatch processing with parameterized queries\nReal-time analytics dashboards\n\n❌ One-off queries\n\nAd-hoc analytics queries\nUnique query patterns\n\n","category":"section"},{"location":"performance/#Batch-Insert-Operations","page":"Performance Guide","title":"Batch Insert Operations","text":"For large-scale data insertion, use insert_batch for dramatic performance improvements.","category":"section"},{"location":"performance/#Performance-Comparison","page":"Performance Guide","title":"Performance Comparison","text":"Database Individual INSERTs Batch INSERT Speedup\nSQLite ~750 rows/s 50-100K rows/s 50-299x\nPostgreSQL ~1K rows/s 400K+ rows/s 400-2016x\nMySQL ~750 rows/s 70-85K rows/s 50-180x","category":"section"},{"location":"performance/#SQLite-Batch-Performance","page":"Performance Guide","title":"SQLite Batch Performance","text":"Rows Individual INSERT Batch INSERT Speedup\n100 132 ms 2.73 ms 48x\n1,000 1,320 ms 4.42 ms 299x\n10,000 13,200 ms 263 ms 50x","category":"section"},{"location":"performance/#PostgreSQL-Batch-Performance-(COPY-FROM-STDIN)","page":"Performance Guide","title":"PostgreSQL Batch Performance (COPY FROM STDIN)","text":"Rows Individual INSERT Batch INSERT Speedup\n100 111 ms 1.62 ms 69x\n1,000 1,110 ms 0.55 ms 2016x\n10,000 11,100 ms 27.5 ms 404x\n\nThroughput: 400,000+ rows/sec sustained","category":"section"},{"location":"performance/#MySQL-Batch-Performance","page":"Performance Guide","title":"MySQL Batch Performance","text":"Rows Individual INSERT Multi-row INSERT Speedup\n100 260 ms 4.92 ms 53x\n1,000 1,319 ms 7.30 ms 181x\n10,000 13,190 ms 55 ms 240x\n\nThroughput: 70-85K rows/sec sustained\n\nNote: MySQL implementation uses multi-row INSERT VALUES. LOAD DATA LOCAL INFILE (300-500K rows/sec) is implemented but requires server/client configuration. See docs/mysql-load-data-setup.md.","category":"section"},{"location":"performance/#Usage","page":"Performance Guide","title":"Usage","text":"# Prepare large dataset\nusers = [\n    (id=i, email=\"user$i@example.com\", active=true)\n    for i in 1:10_000\n]\n\n# Batch insert (automatically optimized per database)\nresult = insert_batch(conn, dialect, registry, :users,\n                      [:id, :email, :active], users)\n\nprintln(\"Inserted $(result.rowcount) rows\")\n# → \"Inserted 10000 rows\"","category":"section"},{"location":"performance/#Automatic-Optimization","page":"Performance Guide","title":"Automatic Optimization","text":"insert_batch automatically selects the best strategy per database:\n\nPostgreSQL: COPY FROM STDIN (binary protocol, 400K+ rows/s)\nMySQL: Multi-row INSERT VALUES with optimal chunking (70-85K rows/s)\nSQLite: Transaction-batched multi-row INSERT (50-100K rows/s)","category":"section"},{"location":"performance/#When-to-Use-4","page":"Performance Guide","title":"When to Use","text":"✅ Data imports - CSV, JSON bulk loading ✅ Data migrations - Moving data between systems ✅ Seed data - Populating test/development databases ✅ Batch processing - ETL pipelines, analytics preprocessing\n\n❌ Small datasets (<100 rows) - Overhead not worth it ❌ Real-time inserts - Use regular execute() for single records\n\nSee benchmark/RESULTS.md in the repository for detailed performance analysis.","category":"section"},{"location":"design/#SQLSketch.jl-–-Design-Document","page":"Design","title":"SQLSketch.jl – Design Document","text":"","category":"section"},{"location":"design/#1.-Purpose","page":"Design","title":"1. Purpose","text":"SQLSketch.jl is an experimental (“toy”) project exploring the design of a typed, composable SQL query core in Julia.\n\nThis project intentionally avoids competing with fully featured ORM frameworks. Instead, it focuses on:\n\nexploring design trade-offs,\nclarifying abstraction boundaries,\nand validating architectural ideas in a small but realistic setting.\n\nThe code is serious; the positioning is not.\n\n","category":"section"},{"location":"design/#2.-Design-Goals","page":"Design","title":"2. Design Goals","text":"SQL is always visible and inspectable\nQuery APIs follow SQL's logical evaluation order\nOutput SQL follows SQL's syntactic order\nStrong typing at query boundaries\nMinimal hidden magic\nClear separation between core primitives and convenience layers\nPostgreSQL-first development with SQLite / MySQL compatibility\n\n","category":"section"},{"location":"design/#3.-Non-Goals","page":"Design","title":"3. Non-Goals","text":"Replacing mature ORMs\nHiding SQL completely\nAutomatic schema diff or online migrations\nFull ActiveRecord-style relations\nBecoming a “standard” Julia DB abstraction\n\n","category":"section"},{"location":"design/#4.-High-Level-Architecture","page":"Design","title":"4. High-Level Architecture","text":"┌─────────────────────────────────────────────────────────────────┐\n│                         Application                             │\n└────────────────────────────┬────────────────────────────────────┘\n                             │\n                             ▼\n┌─────────────────────────────────────────────────────────────────┐\n│                   Extras Layer (optional)                       │\n├─────────────────────────────────────────────────────────────────┤\n│  • Migration runner (apply_migrations, migration_status)        │\n│  • Placeholder syntax (p_)                                      │\n│  • Future: Repository patterns, CRUD helpers, Schema macros     │\n└────────────────────────────┬────────────────────────────────────┘\n                             │\n                             ▼\n┌─────────────────────────────────────────────────────────────────┐\n│              Core Layer (SQLSketch.Core)                        │\n├─────────────────────────────────────────────────────────────────┤\n│                                                                 │\n│  Expression AST ──┐                                             │\n│                   │                                             │\n│                   ▼                                             │\n│              Query AST ──► SQL Compilation ──► Execute ──► Map  │\n│                                     │              │         │  │\n│                                     │              │         │  │\n│                           Dialect ──┘     Driver ──┘         │  │\n│                                                              │  │\n│                                            CodecRegistry ────┘  │\n│                                                                 │\n└─────────────────────────────────────────────────────────────────┘","category":"section"},{"location":"design/#5.-Core-vs-Extras-Layer","page":"Design","title":"5. Core vs Extras Layer","text":"SQLSketch.jl is intentionally designed as a two-layer system:\n\na small, stable Core layer\nan optional, disposable Extras layer\n\nThis separation is fundamental to the project's goals.\n\n","category":"section"},{"location":"design/#5.1-Core-Layer","page":"Design","title":"5.1 Core Layer","text":"The Core layer defines the essential primitives required to build, compile, and execute SQL queries in a principled and inspectable way.\n\nThe Core layer is designed to be:\n\nminimal\nexplicit\nstable over time\nindependent of application-specific patterns","category":"section"},{"location":"design/#Core-Responsibilities","page":"Design","title":"Core Responsibilities","text":"The Core layer is responsible for:\n\nQuery and Expression AST\nSQL compilation\nDialect abstraction (PostgreSQL / MySQL / SQLite)\nDriver abstraction (connection, execution, transactions)\nParameter binding\nRow decoding and mapping\nTransaction management\nError normalization\nObservability hooks (logging / tracing)\n\nThe Core layer does not attempt to provide a full ORM experience.\n\n","category":"section"},{"location":"design/#5.2-Extras-Layer","page":"Design","title":"5.2 Extras Layer","text":"The Extras layer provides convenience abstractions built on top of the Core.\n\nIt exists to improve ergonomics, not to redefine semantics.\n\nThe Extras layer is explicitly considered optional and replaceable.","category":"section"},{"location":"design/#Extras-Layer-Responsibilities","page":"Design","title":"Extras Layer Responsibilities","text":"Typical responsibilities of the Extras layer include:\n\nRepository patterns\nCRUD helpers\nRelation handling and preloading\nSchema definition macros\nDDL generation and diffing\nValidation-related sugar\nMigration application (runner)\n\nAll Extras-layer features must be expressible purely in terms of Core APIs.\n\n","category":"section"},{"location":"design/#5.3-Design-Rationale","page":"Design","title":"5.3 Design Rationale","text":"This separation allows SQLSketch.jl to:\n\navoid over-committing to a single ORM style\nremain useful for both applications and data workflows\nkeep the Core small enough to reason about\nexperiment with higher-level abstractions without breaking the foundation\n\nIn other words:\n\nCore defines \"what is possible\"; Extras defines \"what is convenient\".\n\n","category":"section"},{"location":"design/#5.4-Stability-Contract","page":"Design","title":"5.4 Stability Contract","text":"The Core layer is expected to be:\n\nbackward-compatible within reason\nconservative in API changes\nexplicit about breaking changes\n\nThe Extras layer is free to evolve, change, or even be rewritten entirely.\n\nThis contract allows SQLSketch.jl to serve as a long-lived design exploration without locking users into premature abstractions.","category":"section"},{"location":"design/#6.-Query-Model","page":"Design","title":"6. Query Model","text":"At the heart of SQLSketch.jl is a typed query model built around explicit structure and predictable transformations.\n\nRather than hiding SQL behind opaque abstractions, the query model mirrors SQL semantics while remaining composable and inspectable.\n\n","category":"section"},{"location":"design/#6.1-Logical-Pipeline-API","page":"Design","title":"6.1 Logical Pipeline API","text":"Query construction follows SQL’s logical evaluation order, not its syntactic order.\n\nThe logical order is:\n\nFROM → JOIN → WHERE → GROUP BY → HAVING → SELECT → ORDER BY → LIMIT\n\nIn SQLSketch.jl, queries are constructed as a pipeline reflecting this order.","category":"section"},{"location":"design/#Example","page":"Design","title":"Example","text":"q = from(:users) |>\n    where(col(:users, :active) == literal(true)) |>\n    order_by(col(:users, :created_at); desc=true) |>\n    limit(10) |>\n    select(UserDTO, col(:users, :id), col(:users, :email))\n\nInternally, the query is represented as an AST. When compiled, it is emitted as syntactically correct SQL:\n\nSELECT \"users\".\"id\", \"users\".\"email\"\nFROM \"users\"\nWHERE \"users\".\"active\" = $1\nORDER BY \"users\".\"created_at\" DESC\nLIMIT 10\n\n","category":"section"},{"location":"design/#6.2-Shape-Preserving-vs-Shape-Changing-Operations","page":"Design","title":"6.2 Shape-Preserving vs Shape-Changing Operations","text":"A key design rule in SQLSketch.jl is that most query operations preserve the output shape.","category":"section"},{"location":"design/#Shape-Preserving-Operations","page":"Design","title":"Shape-Preserving Operations","text":"The following operations do not change the query’s output type:\n\nfrom\njoin\nwhere\ngroup_by\nhaving\norder_by\nlimit\noffset\ndistinct\n\nThese operations refine which rows are returned, not what a row looks like.\n\n","category":"section"},{"location":"design/#6.3-The-Role-of-select","page":"Design","title":"6.3 The Role of select","text":"The select operation is the only operation allowed to change the output type of a query.\n\nThis rule provides:\n\npredictable type flow\neasier reasoning about query transformations\na clear boundary for data shaping","category":"section"},{"location":"design/#Examples","page":"Design","title":"Examples","text":"Selecting into a struct:\n\nq |> select(UserDTO, col(:users, :id), col(:users, :email))\n\nSelecting into a NamedTuple:\n\nq |> select(NamedTuple, col(:users, :id), col(:users, :email))\n\n","category":"section"},{"location":"design/#6.4-Output-Type-(OutT)","page":"Design","title":"6.4 Output Type (OutT)","text":"Each query is parameterized by an output type:\n\nSelect{OutT}\n\nThe output type determines:\n\nhow rows are decoded\nhow validation is applied (if any)\nwhat the user receives from fetch_all, fetch_one, or fetch_maybe\n\nThe Core layer treats OutT as an opaque type and relies on constructors and codecs to enforce invariants.\n\n","category":"section"},{"location":"design/#6.5-Joins-and-Composite-Results","page":"Design","title":"6.5 Joins and Composite Results","text":"JOIN operations combine multiple row sources.\n\nBy default, join results are represented as NamedTuple values, preserving all columns explicitly.\n\nExample:\n\nfrom(:users) |>\n    join(:orders, col(:users, :id) == col(:orders, :user_id); kind=:inner)\n\nThis produces rows as NamedTuple values with all columns from both tables.\n\nMapping into a domain-specific type requires an explicit select.\n\n","category":"section"},{"location":"design/#6.6-Rationale","page":"Design","title":"6.6 Rationale","text":"This query model intentionally avoids:\n\nimplicit projections\nautomatic relation materialization\nsilent type changes\n\nInstead, it favors explicitness and local reasoning.\n\nBy constraining when and how the output type changes, SQLSketch.jl makes complex queries easier to understand, refactor, and debug.","category":"section"},{"location":"design/#7.-SQL-Transparency","page":"Design","title":"7. SQL Transparency","text":"A core principle of SQLSketch.jl is that SQL is never hidden.\n\nThe library treats SQL as a first-class artifact that users are encouraged to inspect, reason about, and debug.\n\n","category":"section"},{"location":"design/#7.1-Inspectable-SQL","page":"Design","title":"7.1 Inspectable SQL","text":"Every query can be inspected before execution.\n\nSQLSketch.jl provides APIs such as:\n\nsql(query) – return the generated SQL string\ncompile(query) – return SQL together with parameter ordering\nexplain(query) – generate an EXPLAIN statement (if supported)\n\nThis design ensures that users are never forced to guess what SQL is actually being executed.\n\n","category":"section"},{"location":"design/#7.2-Observability-Oriented-Design","page":"Design","title":"7.2 Observability-Oriented Design","text":"SQL transparency is also reflected in observability features.\n\nThe Core layer supports query hooks that receive:\n\nraw SQL\nparameter metadata\nexecution timing\nrow counts (when available)\nexecution errors\n\nThis enables straightforward integration with logging, tracing, and metrics systems without patching internals.\n\n","category":"section"},{"location":"design/#8.-Expression-Model","page":"Design","title":"8. Expression Model","text":"SQLSketch.jl represents SQL conditions and expressions explicitly using an Expression AST.\n\nExpressions are not strings. They are structured values that can be inspected, transformed, and compiled in a dialect-aware manner.\n\n","category":"section"},{"location":"design/#8.1-Expression-AST","page":"Design","title":"8.1 Expression AST","text":"Examples of expression nodes include:\n\ncolumn references\nliteral values\nbound parameters\nbinary operators (=, <, AND, OR, etc.)\nunary operators (NOT, IS NULL, etc.)\nsubquery expressions (IN, EXISTS)\n\nExpressions form trees that are embedded into query AST nodes such as WHERE, ON, or HAVING.\n\n","category":"section"},{"location":"design/#8.2-Explicit-Expressions","page":"Design","title":"8.2 Explicit Expressions","text":"The Core API always allows expressions to be specified explicitly.\n\nExample:\n\nwhere(q, col(:users, :email) == param(String, :email))\n\nThis form is unambiguous and works uniformly across all query shapes, including joins, subqueries, and correlated queries.\n\n","category":"section"},{"location":"design/#9.-Placeholder-Design","page":"Design","title":"9. Placeholder Design","text":"To improve ergonomics, SQLSketch.jl optionally supports placeholder-based expression construction.\n\nHowever, placeholders are never required by the Core layer.\n\n","category":"section"},{"location":"design/#9.1-Optional-Placeholder-(p_)","page":"Design","title":"9.1 Optional Placeholder (p_)","text":"The p_ placeholder function provides syntactic sugar for parameters:\n\n# Using placeholder\nemail_param = p_(:email, String)\nq = from(:users) |>\n    where(col(:users, :email) == email_param)\n\n# Execute with parameter value\nfetch_one(conn, q, email_param => \"alice@example.com\")\n\nThis is equivalent to the explicit form:\n\nq = from(:users) |>\n    where(col(:users, :email) == param(String, :email))\n\n","category":"section"},{"location":"design/#9.2-Why-Placeholders-Are-Optional","page":"Design","title":"9.2 Why Placeholders Are Optional","text":"Placeholders are not mandatory for several reasons:\n\nthey can become ambiguous in multi-join queries\nthey add indirection during debugging\nthey complicate core API contracts\n\nFor these reasons:\n\nthe Core layer always accepts explicit expressions\nplaceholder-based syntax is treated as optional sugar\nboth styles can coexist in the same codebase\n\n","category":"section"},{"location":"design/#9.3-Design-Rationale","page":"Design","title":"9.3 Design Rationale","text":"By separating expression semantics from expression syntax, SQLSketch.jl achieves the following:\n\nthe Core remains small and explicit\nergonomics can evolve independently\nadvanced queries remain readable and debuggable\n\nThis approach balances usability with long-term maintainability.","category":"section"},{"location":"design/#10.-Dialect-and-Driver-Abstraction","page":"Design","title":"10. Dialect and Driver Abstraction","text":"SQLSketch.jl explicitly separates what SQL is generated from how SQL is executed.\n\nThis separation is achieved through two orthogonal abstractions:\n\nDialect: SQL generation and database semantics\nDriver: connection management and execution\n\n","category":"section"},{"location":"design/#10.1-Dialect","page":"Design","title":"10.1 Dialect","text":"A Dialect represents a database’s SQL syntax and semantic differences.\n\nEach supported database provides its own Dialect implementation (e.g. SQLite, PostgreSQL, MySQL).","category":"section"},{"location":"design/#Dialect-Responsibilities","page":"Design","title":"Dialect Responsibilities","text":"A Dialect is responsible for:\n\ngenerating SQL strings from query ASTs\nquoting identifiers (tables, columns, aliases)\ndefining placeholder syntax (?, $1, etc.)\ncompiling DDL statements\nreporting supported features via capabilities\n\nDialect implementations are pure: they do not manage connections or execute SQL.\n\n","category":"section"},{"location":"design/#10.2-Driver","page":"Design","title":"10.2 Driver","text":"A Driver represents the execution layer for a specific database backend.\n\nDrivers handle all interactions with the underlying database client (e.g. DBInterface, libpq, mysqlclient).","category":"section"},{"location":"design/#Driver-Responsibilities","page":"Design","title":"Driver Responsibilities","text":"A Driver is responsible for:\n\nopening and closing connections\npreparing statements\nexecuting SQL statements\nbinding parameters\nmanaging transactions\nhandling cancellation and timeouts (if supported)\n\nDrivers do not interpret query semantics or perform type conversion.\n\n","category":"section"},{"location":"design/#10.3-Why-Separate-Dialect-and-Driver","page":"Design","title":"10.3 Why Separate Dialect and Driver","text":"Separating Dialect and Driver provides several benefits:\n\nSQL generation can be tested without a database\nmultiple drivers can share a dialect\ndialect logic remains independent of client libraries\nfeature differences are made explicit\n\nThis design avoids conflating SQL semantics with execution mechanics.\n\n","category":"section"},{"location":"design/#11.-Capability-System","page":"Design","title":"11. Capability System","text":"Database systems differ in supported features and behavior. SQLSketch.jl makes these differences explicit using a capability system.\n\n","category":"section"},{"location":"design/#11.1-Capabilities","page":"Design","title":"11.1 Capabilities","text":"Capabilities describe optional database features, such as:\n\nCommon Table Expressions (CTE)\nRETURNING clauses\nUPSERT / ON CONFLICT\nwindow functions\nbulk copy operations\nstatement cancellation\nsavepoints\n\nEach Dialect reports which capabilities it supports.\n\n","category":"section"},{"location":"design/#11.2-Capability-Based-Behavior","page":"Design","title":"11.2 Capability-Based Behavior","text":"Capabilities influence behavior in two primary ways:\n\nEarly failure If a query requires an unsupported capability, compilation fails with a clear error.\nGraceful degradation When possible, a Dialect may emit an alternative SQL formulation that avoids the unsupported feature.\n\nThis ensures that feature differences are visible and intentional.\n\n","category":"section"},{"location":"design/#11.3-Database-Specific-Extensions","page":"Design","title":"11.3 Database-Specific Extensions","text":"Some features are inherently database-specific.\n\nRather than forcing these into the Core API, SQLSketch.jl treats them as explicit extensions guarded by capability checks.\n\nExample (conceptual):\n\n# Hypothetical PostgreSQL COPY FROM support\nif supports(dialect, CAP_BULK_COPY)\n    bulk_copy_from(conn, :table, source)\nelse\n    error(\"BULK COPY is not supported by this database\")\nend\n\nThis approach keeps the Core API minimal while still allowing advanced database-specific functionality.\n\n","category":"section"},{"location":"design/#11.4-Rationale","page":"Design","title":"11.4 Rationale","text":"By combining Dialect abstraction with an explicit capability system, SQLSketch.jl achieves:\n\npredictable cross-database behavior\nclear visibility into feature differences\na stable foundation for experimentation\na clean boundary between portable and non-portable code\n\nThis design avoids both lowest-common-denominator APIs and accidental reliance on database-specific behavior.","category":"section"},{"location":"design/#12.-Type-Conversion-and-CodecRegistry","page":"Design","title":"12. Type Conversion and CodecRegistry","text":"SQLSketch.jl centralizes all database-to-Julia type conversion in a dedicated component called CodecRegistry.\n\nThis design explicitly separates:\n\nSQL semantics (Dialect)\nexecution mechanics (Driver)\ndata representation and invariants (CodecRegistry)\n\n","category":"section"},{"location":"design/#12.1-Motivation","page":"Design","title":"12.1 Motivation","text":"Databases and Julia have fundamentally different type systems.\n\nExamples include:\n\nNULL handling\nUUID representation\nDate / DateTime precision\nJSON storage formats\nSQLite’s dynamic typing\n\nIf handled implicitly, these differences quickly lead to inconsistent behavior and subtle bugs.\n\nSQLSketch.jl addresses this by making type conversion explicit and centralized.\n\n","category":"section"},{"location":"design/#12.2-CodecRegistry","page":"Design","title":"12.2 CodecRegistry","text":"The CodecRegistry defines how values are:\n\nencoded before being sent to the database\ndecoded when read from the database\n\nEach Julia type that participates in queries or result mapping is associated with a codec.\n\nResponsibilities of CodecRegistry include:\n\nencoding Julia values into database-compatible representations\ndecoding database values into Julia types\nenforcing a consistent NULL policy\nnormalizing backend-specific quirks\n\n","category":"section"},{"location":"design/#12.3-NULL-Policy","page":"Design","title":"12.3 NULL Policy","text":"NULL handling is a global policy decision.\n\nSQLSketch.jl supports configurable NULL policies, such as:\n\nMissing-based representation (recommended)\nNothing-based representation\n\nThe chosen policy is applied consistently across:\n\nquery parameters\nresult decoding\nstruct construction\n\nThis avoids mixing NULL semantics within a single application.\n\n","category":"section"},{"location":"design/#12.4-Database-Specific-Type-Handling","page":"Design","title":"12.4 Database-Specific Type Handling","text":"","category":"section"},{"location":"design/#PostgreSQL-(Primary-Target)","page":"Design","title":"PostgreSQL (Primary Target)","text":"PostgreSQL is the primary development target with rich native type support:\n\nNative UUID type\nJSONB for structured data\nPrecise timestamp handling with timezone support\nArrays and composite types\nFull ACID compliance with strict type checking","category":"section"},{"location":"design/#SQLite-(Development-and-Testing)","page":"Design","title":"SQLite (Development and Testing)","text":"SQLite is supported as a lightweight backend for local development and testing.\n\nBecause SQLite is dynamically typed, the CodecRegistry plays a critical role in enforcing invariants to maintain PostgreSQL compatibility.\n\nExamples include:\n\nrepresenting UUIDs as TEXT (PostgreSQL uses native UUID)\nnormalizing DateTime values (PostgreSQL has precise TIMESTAMP WITH TIME ZONE)\nenforcing boolean semantics (PostgreSQL has native BOOLEAN)\nvalidating decoded values before struct construction\n\nThis ensures that SQLite-based testing remains meaningful and compatible with PostgreSQL production deployments.\n\n","category":"section"},{"location":"design/#13.-Query-Execution-Model","page":"Design","title":"13. Query Execution Model","text":"SQLSketch.jl provides a clear separation between side-effecting operations and data retrieval operations.\n\nThis distinction is fundamental to the execution API design.\n\n","category":"section"},{"location":"design/#13.1-Execute-vs-Fetch","page":"Design","title":"13.1 Execute vs Fetch","text":"The execution layer provides two categories of functions:","category":"section"},{"location":"design/#execute-Side-Effects-Only","page":"Design","title":"execute - Side Effects Only","text":"execute(conn, query) -> Int64\n\nPurpose: Execute SQL statements that produce side effects but do not return data.\n\nReturns: Number of affected rows (for DML) or 0 (for DDL).\n\nUse cases:\n\nINSERT without RETURNING\nUPDATE without RETURNING\nDELETE without RETURNING\nCREATE TABLE, ALTER TABLE, DROP TABLE\nCREATE INDEX, DROP INDEX\n\nExample:\n\n# Insert without retrieving data\nq = insert_into(:users, [:email, :name]) |>\n    values([literal(\"alice@example.com\"), literal(\"Alice\")])\n\nrows_affected = execute(conn, q)\n# → 1","category":"section"},{"location":"design/#fetch_*-Data-Retrieval","page":"Design","title":"fetch_* - Data Retrieval","text":"fetch_all(conn, query, T) -> Vector{T}\nfetch_one(conn, query, T) -> T\nfetch_maybe(conn, query, T) -> Union{T, Nothing}\n\nPurpose: Execute SQL statements that return data.\n\nReturns: Decoded rows as Julia values (structs, NamedTuples, etc.)\n\nUse cases:\n\nSELECT queries\nINSERT/UPDATE/DELETE with RETURNING\n\nExample:\n\n# Retrieve data\nq = from(:users) |>\n    where(col(:users, :active) == literal(true)) |>\n    select(NamedTuple, col(:users, :id), col(:users, :email))\n\nusers = fetch_all(conn, q, NamedTuple)\n# → [{id: 1, email: \"alice@example.com\"}, ...]\n\n# Insert with RETURNING\nq = insert_into(:users, [:email, :name]) |>\n    values([literal(\"bob@example.com\"), literal(\"Bob\")]) |>\n    returning(col(:users, :id))\n\nuser_id = fetch_one(conn, q, Int64)\n# → 42\n\n","category":"section"},{"location":"design/#13.2-Design-Rationale","page":"Design","title":"13.2 Design Rationale","text":"This separation provides several benefits:\n\nIntent clarity: The function name signals whether you expect data back.\nType safety: fetch_* requires explicit result type, preventing type errors.\nPerformance: execute can skip row decoding overhead.\nError detection: Using execute on a SELECT or fetch_* on a CREATE TABLE makes the mistake obvious.\n\n","category":"section"},{"location":"design/#13.3-Unified-API","page":"Design","title":"13.3 Unified API","text":"Both execute and fetch_* accept the same connection types:\n\nConnection (direct connection)\nTransactionHandle (within a transaction)\nSavepointHandle (within a savepoint)\n\nThis means you can use the same code pattern regardless of transaction context:\n\n# Direct execution\nexecute(conn, insert_query)\n\n# Within transaction\ntransaction(conn) do tx\n    execute(tx, insert_query)  # Same API\n    users = fetch_all(tx, select_query, User)  # Same API\nend\n\n","category":"section"},{"location":"design/#14.-Transaction-Model","page":"Design","title":"14. Transaction Model","text":"Transaction handling is a Core responsibility in SQLSketch.jl.\n\nTransactions are designed to be:\n\nexplicit\ncomposable\npredictable\nsafe by default\n\n","category":"section"},{"location":"design/#14.1-Transaction-Semantics","page":"Design","title":"14.1 Transaction Semantics","text":"Transactions follow a simple and strict rule:\n\nif the transaction block completes normally → commit\nif an exception escapes the block → rollback\n\nExample:\n\ntransaction(conn) do tx\n    # Insert user\n    insert_q = insert_into(:users, [:email, :name]) |>\n        values([literal(\"alice@example.com\"), literal(\"Alice\")])\n    execute(tx, insert_q)\n\n    # Update settings\n    update_q = update(:settings) |>\n        set(:theme, literal(\"dark\")) |>\n        where(col(:settings, :user_id) == literal(1))\n    execute(tx, update_q)\nend\n\nIf any operation inside the block fails, all changes are rolled back.\n\n","category":"section"},{"location":"design/#14.2-Transaction-Handles","page":"Design","title":"14.2 Transaction Handles","text":"Transaction handles are designed to be connection-compatible.\n\nThis means that within a transaction block:\n\nthe same query execution APIs can be used\ncode does not need to distinguish between a connection and a transaction\n\nThis simplifies application code and avoids branching logic.\n\n","category":"section"},{"location":"design/#14.3-Isolation-and-Advanced-Features","page":"Design","title":"14.3 Isolation and Advanced Features","text":"Transaction options such as:\n\nisolation level\nread-only mode\nsavepoints\n\nare expressed explicitly and guarded by capabilities.\n\nUnsupported options result in early, descriptive errors.\n\n","category":"section"},{"location":"design/#14.4-Rationale","page":"Design","title":"14.4 Rationale","text":"By keeping transaction semantics simple and explicit, SQLSketch.jl avoids:\n\nimplicit nested transaction behavior\nhidden auto-commit rules\nbackend-specific surprises\n\nThe transaction model favors clarity and correctness over maximum flexibility, which aligns with the project’s experimental and educational goals.","category":"section"},{"location":"design/#15.-DDL-and-Migration-Design","page":"Design","title":"15. DDL and Migration Design","text":"SQLSketch.jl treats schema management as a necessary but carefully scoped responsibility.\n\nThe goal is to support reliable schema evolution without turning the Core layer into a full schema-management framework.\n\n","category":"section"},{"location":"design/#14.1-Scope-of-Responsibility","page":"Design","title":"14.1 Scope of Responsibility","text":"The Core layer is responsible for:\n\napplying migrations\ntracking which migrations have been applied\ncompiling DDL statements in a dialect-aware way\n\nThe Core layer explicitly does not:\n\ninfer schema differences\nauto-generate migrations\nmanage online or zero-downtime migrations\n\nThese higher-level concerns are intentionally left to the Extras layer or external tooling.\n\n","category":"section"},{"location":"design/#14.2-Migration-Runner","page":"Design","title":"14.2 Migration Runner","text":"SQLSketch.jl includes a minimal migration runner.\n\nThe runner’s responsibilities include:\n\ndiscovering migration files\napplying migrations in a deterministic order\nrecording applied versions\npreventing accidental re-application\n\nA dedicated metadata table (e.g. schema_migrations) is used to track applied migrations.\n\n","category":"section"},{"location":"design/#14.3-Migration-Format","page":"Design","title":"14.3 Migration Format","text":"Migrations may be expressed in one of the following forms:\n\nraw SQL files\nstructured DDL operations compiled by the Dialect\n\nThe Core layer treats migrations as opaque units of change.\n\nThis allows users to:\n\nwrite database-specific SQL when needed\nkeep full control over schema evolution\navoid leaky abstractions in DDL generation\n\n","category":"section"},{"location":"design/#14.4-Dialect-Aware-DDL-Compilation","page":"Design","title":"14.4 Dialect-Aware DDL Compilation","text":"DDL statements are compiled through the Dialect abstraction.\n\nThis allows:\n\ncorrect identifier quoting\nappropriate data type mapping\nexplicit handling of unsupported features\n\nIf a DDL operation cannot be represented for a given Dialect, the system fails early with a descriptive error.\n\n","category":"section"},{"location":"design/#14.5-Cross-Database-Migration-Support","page":"Design","title":"14.5 Cross-Database Migration Support","text":"","category":"section"},{"location":"design/#PostgreSQL-(Primary-Target)-2","page":"Design","title":"PostgreSQL (Primary Target)","text":"Migrations are primarily designed for PostgreSQL with full support for:\n\nComprehensive constraint enforcement (CHECK, UNIQUE, FOREIGN KEY)\nRich data types (UUID, JSONB, arrays, timestamps with timezone)\nAdvanced features (partial indexes, exclusion constraints)","category":"section"},{"location":"design/#SQLite-(Development-and-Testing)-2","page":"Design","title":"SQLite (Development and Testing)","text":"SQLite is supported for local development and rapid iteration.\n\nWhen applying the same migration set to SQLite, note that:\n\nSQLite may accept a broader range of schemas (more permissive)\nSome constraints behave differently (e.g., FOREIGN KEY enforcement)\nRuntime normalization is enforced via CodecRegistry to maintain PostgreSQL compatibility\n\nThis approach enables:\n\nFast local testing without PostgreSQL infrastructure\nEarly detection of schema issues before PostgreSQL deployment\nConsistent migration files across development and production databases\n\n","category":"section"},{"location":"design/#14.6-Rationale","page":"Design","title":"14.6 Rationale","text":"By limiting the Core’s responsibility to migration application, SQLSketch.jl avoids:\n\noverly complex schema DSLs\nbrittle diff-based migration generation\ntight coupling between schema and query APIs\n\nThis design keeps schema management explicit, inspectable, and aligned with the project’s exploratory nature.","category":"section"},{"location":"design/#16.-Observability","page":"Design","title":"16. Observability","text":"SQLSketch.jl is designed to make database interactions observable by default.\n\nRather than hiding execution details behind abstractions, the Core layer exposes hooks and inspection points that allow users to understand what is happening at runtime.\n\n","category":"section"},{"location":"design/#15.1-Query-Hooks","page":"Design","title":"15.1 Query Hooks","text":"The Core layer supports query-level hooks that receive structured events, including:\n\nthe generated SQL string\nparameter metadata (keys and order)\nexecution timing\nrow counts (when available)\nexecution errors\n\nThese hooks enable integration with:\n\nlogging systems\ntracing frameworks\nmetrics collection\nad-hoc debugging tools\n\nObservability is treated as a first-class concern, not an afterthought.\n\n","category":"section"},{"location":"design/#15.2-Explain-and-Debugging-Support","page":"Design","title":"15.2 Explain and Debugging Support","text":"SQLSketch.jl provides explicit support for query inspection via:\n\nsql(query) for raw SQL inspection\ncompile(query) for SQL and parameter ordering\nexplain(query) for database execution plans (when supported)\n\nThis allows performance issues to be investigated without instrumenting internal code paths.\n\n","category":"section"},{"location":"design/#17.-Testing-Strategy","page":"Design","title":"17. Testing Strategy","text":"Testing is structured to reflect the layered architecture and multi-database goals of SQLSketch.jl.\n\n","category":"section"},{"location":"design/#17.1-Unit-Tests","page":"Design","title":"17.1 Unit Tests","text":"Unit tests focus on pure logic and do not require a database.\n\nTypical unit test targets include:\n\nExpression and Query AST construction\nSQL compilation for each Dialect\nCapability reporting\nCodecRegistry encode/decode behavior\n\nThese tests are fast and form the bulk of the test suite.\n\n","category":"section"},{"location":"design/#17.2-Integration-Tests-(SQLite)","page":"Design","title":"17.2 Integration Tests (SQLite)","text":"Integration tests use SQLite in-memory databases.\n\nThey validate:\n\nend-to-end query execution\nparameter binding\nrow decoding and mapping\ntransaction commit and rollback\nmigration application\n\nSQLite enables fast, deterministic tests suitable for CI environments.\n\n","category":"section"},{"location":"design/#17.3-Compatibility-Tests-(PostgreSQL-/-MySQL)","page":"Design","title":"17.3 Compatibility Tests (PostgreSQL / MySQL)","text":"A small number of compatibility tests are run against PostgreSQL and MySQL.\n\nThese tests focus on:\n\ndialect-specific SQL generation\nfeature-gated capabilities (e.g. RETURNING, UPSERT)\ntype behavior differences\ntransaction semantics\n\nCompatibility tests are intentionally limited in scope to avoid slowing down development.\n\n","category":"section"},{"location":"design/#18.-Project-Positioning","page":"Design","title":"18. Project Positioning","text":"SQLSketch.jl is intentionally positioned as:\n\nexploratory\neducational\nexperimental\nreplaceable\n\nIt is not intended to be a drop-in replacement for mature ORMs or database abstraction layers.\n\n","category":"section"},{"location":"design/#17.1-Design-Exploration","page":"Design","title":"17.1 Design Exploration","text":"The primary goal of SQLSketch.jl is to explore:\n\nhow far a small, principled SQL core can go\nwhich abstractions are useful or harmful\nhow to balance type safety with SQL transparency\nhow Julia’s strengths apply to query construction\n\n","category":"section"},{"location":"design/#17.2-Evolution-and-Exit-Strategy","page":"Design","title":"17.2 Evolution and Exit Strategy","text":"If ideas explored in SQLSketch.jl prove valuable, they may be:\n\nextracted into separate libraries\nrenamed and formalized\nupstreamed into more production-oriented projects\n\nConversely, if certain ideas do not work well, they can be discarded without regret.\n\nThis flexibility is a deliberate design choice.\n\n","category":"section"},{"location":"design/#19.-Summary","page":"Design","title":"19. Summary","text":"SQLSketch.jl explores how to build a typed, composable SQL core without becoming a full ORM.\n\nIt prioritizes:\n\nclarity over completeness\nexplicitness over convenience\ndesign exploration over polish\n\nBy keeping the Core small and principled, SQLSketch.jl provides a safe environment for experimentation while remaining grounded in real-world database usage.","category":"section"},{"location":"#SQLSketch.jl","page":"Home","title":"SQLSketch.jl","text":"A type-safe, composable SQL query builder for Julia with PostgreSQL as the primary target.","category":"section"},{"location":"#Overview","page":"Home","title":"Overview","text":"SQLSketch.jl provides a fluent API for constructing SQL queries that are checked at compile time while remaining transparent and inspectable. It's designed with PostgreSQL as the first-class target, supporting rich native types (UUID, JSONB, ARRAY) and advanced SQL features.\n\nKey features:\n\nType-safe query building - Output types tracked through the pipeline\nSQL transparency - All queries inspectable before execution\nShape-preserving semantics - Predictable type transformations\nPostgreSQL-first - Full support for PostgreSQL features\nComposable API - Natural pipeline syntax with currying\nTransaction support - First-class transaction and savepoint handling\nMigration system - Timestamp-based migrations with checksums\nDDL support - Create tables, indexes, and constraints","category":"section"},{"location":"#Quick-Example","page":"Home","title":"Quick Example","text":"using SQLSketch\nusing SQLSketch.Drivers: PostgreSQLDriver\n\n# Connect to PostgreSQL\ndriver = PostgreSQLDriver(\"host=localhost dbname=mydb user=myuser\")\n\n# Type-safe query building\nstruct User\n    id::Int64\n    email::String\n    created_at::DateTime\nend\n\nq = from(:users) |>\n    where(col(:users, :active) == literal(true)) |>\n    order_by(col(:users, :created_at); desc=true) |>\n    limit(10) |>\n    select(User,\n           col(:users, :id),\n           col(:users, :email),\n           col(:users, :created_at))\n\n# Execute and get typed results\nusers = fetch_all(driver, q)\n# Vector{User}","category":"section"},{"location":"#Design-Philosophy","page":"Home","title":"Design Philosophy","text":"SQLSketch follows these core principles:\n\nType Safety First - Query output types are tracked at compile time\nSQL Transparency - Never hide the SQL; always inspectable\nExplicit over Implicit - No magic; clear intent\nPostgreSQL-First - Leverage PostgreSQL's rich feature set\nTest-Driven - Comprehensive tests, database-optional when possible\n\nSee Design for detailed design rationale.","category":"section"},{"location":"#Architecture:-Core-vs-Extras","page":"Home","title":"Architecture: Core vs Extras","text":"SQLSketch is structured in two layers with distinct purposes:","category":"section"},{"location":"#Core-Layer-Minimal,-Explicit,-Stable","page":"Home","title":"Core Layer - Minimal, Explicit, Stable","text":"The Core layer provides the essential building blocks for SQL interaction:\n\nQuery and Expression AST - Type-safe query construction\nDialect abstraction - PostgreSQL, SQLite support\nDriver abstraction - Connection and execution\nCodecRegistry - Type conversion between Julia and SQL\nTransaction management - ACID guarantees\nDDL operations - Schema creation and modification\n\nCore principles:\n\n✅ Type safety over convenience\n✅ Explicit over implicit\n✅ No magic, no hidden behavior\n✅ All operations are inspectable\n✅ Minimal dependencies\n\nExample - Core only:\n\nusing SQLSketch.Core\n\n# Explicit query construction\nq = from(:users) |>\n    where(col(:users, :id) == literal(42)) |>\n    select(NamedTuple, col(:users, :id), col(:users, :email))\n\n# Execute with explicit connection\nusers = fetch_all(driver, q)","category":"section"},{"location":"#Extras-Layer-Convenient,-Optional,-Replaceable","page":"Home","title":"Extras Layer - Convenient, Optional, Replaceable","text":"The Extras layer provides convenience features built on top of Core:\n\nCurrent Extras:\n\nPlaceholder syntax (p_) - Syntactic sugar for single-table queries\nMigration runner - Timestamp-based schema migrations\n\nFuture Extras (planned):\n\nRepository pattern helpers\nCRUD shortcuts\nQuery builder macros\nActive Record-style wrappers\n\nExtras principles:\n\n✅ Built entirely on Core APIs\n✅ Optional - can be replaced with custom implementations\n✅ Convenience over purity\n✅ Can use \"magic\" for ergonomics\n\nExample - Using Extras:\n\nusing SQLSketch.Extras\n\n# Placeholder syntax sugar\nuser_id = p_(:user_id, Int64)\nq = from(:users) |>\n    where(col(:users, :id) == user_id) |>\n    select(NamedTuple, col(:users, :id), col(:users, :email))\n\n# Execute with parameters\nuser = fetch_one(driver, q, user_id => 42)\n\nWhy this separation?\n\nClarity of purpose: Core is stable and minimal; Extras can evolve freely\nReplaceability: Don't like the Extras? Build your own on Core\nLearning curve: Start with Core for fundamentals, add Extras for productivity\nMaintenance: Core stays focused; Extras can experiment\n\nSee Design - Core vs Extras Layer for more details.","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"using Pkg\nPkg.add(url=\"https://github.com/daikichiba9511/SQLSketch.jl\")","category":"section"},{"location":"#Database-Support","page":"Home","title":"Database Support","text":"","category":"section"},{"location":"#PostgreSQL-(Primary)","page":"Home","title":"PostgreSQL (Primary)","text":"SQLSketch is designed with PostgreSQL as the primary target:\n\nusing SQLSketch.Drivers: PostgreSQLDriver\ndriver = PostgreSQLDriver(\"host=localhost dbname=mydb user=myuser password=mypass\")\n\nSupported PostgreSQL features:\n\nNative types: UUID, JSONB, ARRAY, BYTEA, TIMESTAMP WITH TIME ZONE\nAdvanced SQL: CTEs, Window Functions, RETURNING, ON CONFLICT\nFull DDL support: CREATE/ALTER/DROP TABLE, CREATE/DROP INDEX\nTransaction features: Savepoints, advisory locks","category":"section"},{"location":"#SQLite-(Development/Testing)","page":"Home","title":"SQLite (Development/Testing)","text":"SQLite is supported for fast local development and CI testing:\n\nusing SQLSketch.Drivers: SQLiteDriver\ndriver = SQLiteDriver(\":memory:\")  # In-memory\n# or\ndriver = SQLiteDriver(\"dev.db\")     # File-based\n\nUse SQLite for:\n\nFast local development\nIntegration tests in CI\nPrototyping\nDevelopment with eventual PostgreSQL deployment","category":"section"},{"location":"#Getting-Started","page":"Home","title":"Getting Started","text":"Start with the Getting Started Guide for a step-by-step introduction.\n\nThen explore:\n\nTutorial - Learn by building a complete application\nAPI Reference - Complete function and type documentation\nPerformance Guide - Optimize query performance with columnar API\nDesign - Understand the architecture and design decisions","category":"section"},{"location":"#Features","page":"Home","title":"Features","text":"","category":"section"},{"location":"#Type-Safe-Query-Building","page":"Home","title":"Type-Safe Query Building","text":"Output types are tracked through the pipeline:\n\nq1 = from(:users)  # Query{NamedTuple}\n\nq2 = q1 |> where(col(:users, :active) == literal(true))\n# Still Query{NamedTuple} - shape-preserving\n\nq3 = q2 |> select(User, col(:users, :id), col(:users, :email))\n# Query{User} - shape-changing","category":"section"},{"location":"#Parameterized-Queries","page":"Home","title":"Parameterized Queries","text":"Safe parameter binding with type checking:\n\nuser_id = p_(:user_id, Int64)\nemail = p_(:email, String)\n\nq = from(:users) |>\n    where((col(:users, :id) == user_id) & (col(:users, :email) == email)) |>\n    select(User, col(:users, :id), col(:users, :email))\n\nuser = fetch_one(driver, q, user_id => 42, email => \"user@example.com\")","category":"section"},{"location":"#DML-with-RETURNING","page":"Home","title":"DML with RETURNING","text":"q = insert_into(:users, [:email, :active]) |>\n    values([literal(\"new@example.com\"), literal(true)]) |>\n    returning(col(:users, :id), col(:users, :created_at))\n\nresult = fetch_one(driver, q)  # NamedTuple{(:id, :created_at)}","category":"section"},{"location":"#Transactions-and-Savepoints","page":"Home","title":"Transactions and Savepoints","text":"result = transaction(driver) do tx\n    user_id = fetch_one(tx, insert_user_query)\n\n    savepoint(tx, :create_profile) do sp\n        execute(sp, create_profile_query)\n    end\n\n    user_id\nend","category":"section"},{"location":"#DDL-Operations","page":"Home","title":"DDL Operations","text":"q = create_table(:users) |>\n    add_column(:id, :integer) |>\n    add_column(:email, :text) |>\n    add_column(:created_at, :timestamp) |>\n    primary_key(:id) |>\n    not_null(:email) |>\n    unique_constraint(:email)\n\nexecute(driver, q)","category":"section"},{"location":"#Window-Functions","page":"Home","title":"Window Functions","text":"q = from(:sales) |>\n    select(NamedTuple,\n           col(:sales, :product),\n           col(:sales, :amount),\n           row_number() |> over(order_by(:amount; desc=true)))","category":"section"},{"location":"#Set-Operations","page":"Home","title":"Set Operations","text":"q1 = from(:users_2024) |> select(NamedTuple, col(:users_2024, :email))\nq2 = from(:users_2025) |> select(NamedTuple, col(:users_2025, :email))\n\nq = set_union(q1, q2, all=false)  # UNION (deduplicated)","category":"section"},{"location":"#Migration-System","page":"Home","title":"Migration System","text":"using SQLSketch.Extras: apply_migrations, migration_status\n\n# Apply all pending migrations\napplied = apply_migrations(conn, dialect, \"migrations/\")\n\n# Check status\nstatus = migration_status(conn, dialect, \"migrations/\")","category":"section"},{"location":"#Project-Status","page":"Home","title":"Project Status","text":"⚠️ Note: This is a toy project for learning purposes.\n\nSQLSketch.jl is a personal learning project to explore:\n\nType-safe query builder design in Julia\nPostgreSQL-first API design\nFluent pipeline APIs with currying\nJulia's type system and multiple dispatch\n\nCurrent status:\n\nPhase 11 (PostgreSQL Dialect) completed\n1712 passing tests\nCurrent phase: Phase 12 - Documentation\n\nNot recommended for production use. This project is intended as a learning exercise and exploration of Julia's capabilities.","category":"section"},{"location":"#License","page":"Home","title":"License","text":"MIT License - see LICENSE file for details.","category":"section"},{"location":"tutorial/#Tutorial:-Building-a-Blog-Application","page":"Tutorial","title":"Tutorial: Building a Blog Application","text":"⚠️ Note: This is a toy project for learning purposes, not intended for production use.\n\nThis tutorial walks through building a complete blog application with SQLSketch.jl, demonstrating key features and best practices.","category":"section"},{"location":"tutorial/#Prerequisites","page":"Tutorial","title":"Prerequisites","text":"using Pkg\nPkg.add(url=\"https://github.com/daikichiba9511/SQLSketch.jl\")\nPkg.add(\"LibPQ\")  # PostgreSQL driver\nPkg.add(\"Dates\")\nPkg.add(\"UUIDs\")","category":"section"},{"location":"tutorial/#1.-Database-Setup","page":"Tutorial","title":"1. Database Setup","text":"First, create a PostgreSQL database and connect:\n\nusing SQLSketch\nusing SQLSketch.Drivers: PostgreSQLDriver\nusing SQLSketch.Dialects: PostgreSQLDialect\nusing Dates\nusing UUIDs\n\n# Connect to PostgreSQL\ndriver = PostgreSQLDriver(\"host=localhost dbname=blog_dev user=postgres password=postgres\")\ndialect = PostgreSQLDialect()","category":"section"},{"location":"tutorial/#2.-Define-Data-Models","page":"Tutorial","title":"2. Define Data Models","text":"Define Julia structs that map to our database tables:\n\n# User model\nstruct User\n    id::UUID\n    email::String\n    username::String\n    created_at::DateTime\nend\n\n# Post model\nstruct Post\n    id::UUID\n    user_id::UUID\n    title::String\n    content::String\n    published::Bool\n    created_at::DateTime\n    updated_at::Union{Nothing,DateTime}\nend\n\n# Comment model\nstruct Comment\n    id::UUID\n    post_id::UUID\n    user_id::UUID\n    content::String\n    created_at::DateTime\nend\n\n# Tag model\nstruct Tag\n    id::Int64\n    name::String\nend","category":"section"},{"location":"tutorial/#3.-Create-Database-Schema","page":"Tutorial","title":"3. Create Database Schema","text":"Use SQLSketch's DDL operations to create tables:\n\n# Create users table\ncreate_users = create_table(:users) |>\n    add_column(:id, :uuid) |>\n    add_column(:email, :text) |>\n    add_column(:username, :text) |>\n    add_column(:created_at, :timestamp) |>\n    primary_key(:id) |>\n    not_null(:email) |>\n    not_null(:username) |>\n    unique_constraint(:email) |>\n    unique_constraint(:username)\n\nexecute(driver, create_users)\n\n# Create posts table\ncreate_posts = create_table(:posts) |>\n    add_column(:id, :uuid) |>\n    add_column(:user_id, :uuid) |>\n    add_column(:title, :text) |>\n    add_column(:content, :text) |>\n    add_column(:published, :boolean) |>\n    add_column(:created_at, :timestamp) |>\n    add_column(:updated_at, :timestamp) |>\n    primary_key(:id) |>\n    not_null(:user_id) |>\n    not_null(:title) |>\n    not_null(:published) |>\n    foreign_key(:user_id, :users, :id)\n\nexecute(driver, create_posts)\n\n# Create comments table\ncreate_comments = create_table(:comments) |>\n    add_column(:id, :uuid) |>\n    add_column(:post_id, :uuid) |>\n    add_column(:user_id, :uuid) |>\n    add_column(:content, :text) |>\n    add_column(:created_at, :timestamp) |>\n    primary_key(:id) |>\n    not_null(:post_id) |>\n    not_null(:user_id) |>\n    not_null(:content) |>\n    foreign_key(:post_id, :posts, :id) |>\n    foreign_key(:user_id, :users, :id)\n\nexecute(driver, create_comments)\n\n# Create tags table\ncreate_tags = create_table(:tags) |>\n    add_column(:id, :serial) |>\n    add_column(:name, :text) |>\n    primary_key(:id) |>\n    not_null(:name) |>\n    unique_constraint(:name)\n\nexecute(driver, create_tags)\n\n# Create posts_tags junction table\ncreate_posts_tags = create_table(:posts_tags) |>\n    add_column(:post_id, :uuid) |>\n    add_column(:tag_id, :integer) |>\n    primary_key(:post_id, :tag_id) |>\n    foreign_key(:post_id, :posts, :id) |>\n    foreign_key(:tag_id, :tags, :id)\n\nexecute(driver, create_posts_tags)\n\n# Create indexes for performance\ncreate_index(:idx_posts_user_id) |> on(:posts, :user_id) |> execute(driver)\ncreate_index(:idx_comments_post_id) |> on(:comments, :post_id) |> execute(driver)\ncreate_index(:idx_posts_created_at) |> on(:posts, :created_at) |> execute(driver)","category":"section"},{"location":"tutorial/#4.-Insert-Data","page":"Tutorial","title":"4. Insert Data","text":"","category":"section"},{"location":"tutorial/#Create-a-User","page":"Tutorial","title":"Create a User","text":"function create_user(driver, email::String, username::String)::User\n    q = insert_into(:users, [:id, :email, :username, :created_at]) |>\n        values([\n            literal(uuid4()),\n            literal(email),\n            literal(username),\n            literal(now())\n        ]) |>\n        returning(\n            col(:users, :id),\n            col(:users, :email),\n            col(:users, :username),\n            col(:users, :created_at)\n        )\n\n    fetch_one(driver, q, User)\nend\n\n# Create a user\nalice = create_user(driver, \"alice@example.com\", \"alice\")\nprintln(\"Created user: $(alice.username) ($(alice.id))\")","category":"section"},{"location":"tutorial/#Create-a-Post","page":"Tutorial","title":"Create a Post","text":"function create_post(driver, user_id::UUID, title::String, content::String)::Post\n    q = insert_into(:posts, [:id, :user_id, :title, :content, :published, :created_at, :updated_at]) |>\n        values([\n            literal(uuid4()),\n            literal(user_id),\n            literal(title),\n            literal(content),\n            literal(false),\n            literal(now()),\n            literal(nothing)\n        ]) |>\n        returning(\n            col(:posts, :id),\n            col(:posts, :user_id),\n            col(:posts, :title),\n            col(:posts, :content),\n            col(:posts, :published),\n            col(:posts, :created_at),\n            col(:posts, :updated_at)\n        )\n\n    fetch_one(driver, q, Post)\nend\n\n# Create a post\npost = create_post(driver, alice.id, \"My First Post\", \"Hello, world!\")\nprintln(\"Created post: $(post.title)\")","category":"section"},{"location":"tutorial/#Add-Comments","page":"Tutorial","title":"Add Comments","text":"function create_comment(driver, post_id::UUID, user_id::UUID, content::String)::Comment\n    q = insert_into(:comments, [:id, :post_id, :user_id, :content, :created_at]) |>\n        values([\n            literal(uuid4()),\n            literal(post_id),\n            literal(user_id),\n            literal(content),\n            literal(now())\n        ]) |>\n        returning(\n            col(:comments, :id),\n            col(:comments, :post_id),\n            col(:comments, :user_id),\n            col(:comments, :content),\n            col(:comments, :created_at)\n        )\n\n    fetch_one(driver, q, Comment)\nend\n\n# Add a comment\ncomment = create_comment(driver, post.id, alice.id, \"First comment!\")","category":"section"},{"location":"tutorial/#5.-Query-Data","page":"Tutorial","title":"5. Query Data","text":"","category":"section"},{"location":"tutorial/#Fetch-All-Published-Posts","page":"Tutorial","title":"Fetch All Published Posts","text":"q = from(:posts) |>\n    where(col(:posts, :published) == literal(true)) |>\n    order_by(col(:posts, :created_at); desc=true) |>\n    select(Post,\n           col(:posts, :id),\n           col(:posts, :user_id),\n           col(:posts, :title),\n           col(:posts, :content),\n           col(:posts, :published),\n           col(:posts, :created_at),\n           col(:posts, :updated_at))\n\npublished_posts = fetch_all(driver, q)","category":"section"},{"location":"tutorial/#Fetch-Posts-with-User-Information","page":"Tutorial","title":"Fetch Posts with User Information","text":"struct PostWithAuthor\n    post_id::UUID\n    title::String\n    content::String\n    author_username::String\n    created_at::DateTime\nend\n\nq = from(:posts) |>\n    join(:users, col(:users, :id) == col(:posts, :user_id); kind=:inner) |>\n    where(col(:posts, :published) == literal(true)) |>\n    order_by(col(:posts, :created_at); desc=true) |>\n    select(PostWithAuthor,\n           col(:posts, :id),\n           col(:posts, :title),\n           col(:posts, :content),\n           col(:users, :username),\n           col(:posts, :created_at))\n\nposts_with_authors = fetch_all(driver, q)\n\nfor post in posts_with_authors\n    println(\"$(post.title) by $(post.author_username)\")\nend","category":"section"},{"location":"tutorial/#Fetch-Post-with-Comments","page":"Tutorial","title":"Fetch Post with Comments","text":"struct PostComment\n    comment_id::UUID\n    content::String\n    author_username::String\n    created_at::DateTime\nend\n\nfunction get_post_comments(driver, post_id::UUID)::Vector{PostComment}\n    q = from(:comments) |>\n        join(:users, col(:users, :id) == col(:comments, :user_id); kind=:inner) |>\n        where(col(:comments, :post_id) == literal(post_id)) |>\n        order_by(col(:comments, :created_at); desc=false) |>\n        select(PostComment,\n               col(:comments, :id),\n               col(:comments, :content),\n               col(:users, :username),\n               col(:comments, :created_at))\n\n    fetch_all(driver, q)\nend\n\ncomments = get_post_comments(driver, post.id)","category":"section"},{"location":"tutorial/#Parameterized-Search","page":"Tutorial","title":"Parameterized Search","text":"search_term = p_(:search, String)\n\nq = from(:posts) |>\n    where(\n        (col(:posts, :title) |> like(literal(\"%Julia%\"))) |\n        (col(:posts, :content) |> like(literal(\"%database%\")))\n    ) |>\n    order_by(col(:posts, :created_at); desc=true) |>\n    select(Post,\n           col(:posts, :id),\n           col(:posts, :user_id),\n           col(:posts, :title),\n           col(:posts, :content),\n           col(:posts, :published),\n           col(:posts, :created_at),\n           col(:posts, :updated_at))\n\nresults = fetch_all(driver, q)","category":"section"},{"location":"tutorial/#Aggregation:-Count-Posts-by-User","page":"Tutorial","title":"Aggregation: Count Posts by User","text":"struct UserPostCount\n    username::String\n    post_count::Int64\nend\n\nq = from(:posts) |>\n    join(:users, col(:users, :id) == col(:posts, :user_id); kind=:inner) |>\n    group_by(col(:users, :username)) |>\n    select(UserPostCount,\n           col(:users, :username),\n           count_star())\n\ncounts = fetch_all(driver, q)\n\nfor row in counts\n    println(\"$(row.username): $(row.post_count) posts\")\nend","category":"section"},{"location":"tutorial/#6.-Update-Data","page":"Tutorial","title":"6. Update Data","text":"","category":"section"},{"location":"tutorial/#Publish-a-Post","page":"Tutorial","title":"Publish a Post","text":"function publish_post(driver, post_id::UUID)\n    q = update(:posts) |>\n        set_(:published, literal(true)) |>\n        set_(:updated_at, literal(now())) |>\n        where(col(:posts, :id) == literal(post_id))\n\n    execute(driver, q)\nend\n\npublish_post(driver, post.id)","category":"section"},{"location":"tutorial/#Edit-Post-Content","page":"Tutorial","title":"Edit Post Content","text":"function edit_post(driver, post_id::UUID, new_title::String, new_content::String)\n    q = update(:posts) |>\n        set_(:title, literal(new_title)) |>\n        set_(:content, literal(new_content)) |>\n        set_(:updated_at, literal(now())) |>\n        where(col(:posts, :id) == literal(post_id))\n\n    execute(driver, q)\nend\n\nedit_post(driver, post.id, \"Updated Title\", \"Updated content!\")","category":"section"},{"location":"tutorial/#7.-Transactions","page":"Tutorial","title":"7. Transactions","text":"Use transactions to ensure data consistency:\n\nfunction create_post_with_tags(driver, user_id::UUID, title::String, content::String, tag_names::Vector{String})\n    transaction(driver) do tx\n        # Create post\n        post_q = insert_into(:posts, [:id, :user_id, :title, :content, :published, :created_at, :updated_at]) |>\n            values([\n                literal(uuid4()),\n                literal(user_id),\n                literal(title),\n                literal(content),\n                literal(false),\n                literal(now()),\n                literal(nothing)\n            ]) |>\n            returning(col(:posts, :id))\n\n        post_id = fetch_one(tx, post_q)\n\n        # Create or find tags and link to post\n        for tag_name in tag_names\n            # Try to insert tag (using ON CONFLICT DO NOTHING for PostgreSQL)\n            tag_q = insert_into(:tags, [:name]) |>\n                values([literal(tag_name)]) |>\n                on_conflict([:name]) |>\n                do_nothing() |>\n                returning(col(:tags, :id))\n\n            # Get tag id\n            tag_id_q = from(:tags) |>\n                where(col(:tags, :name) == literal(tag_name)) |>\n                select(NamedTuple, col(:tags, :id))\n\n            tag_id = fetch_one(tx, tag_id_q)\n\n            # Link post and tag\n            link_q = insert_into(:posts_tags, [:post_id, :tag_id]) |>\n                values([literal(post_id), literal(tag_id)])\n\n            execute(tx, link_q)\n        end\n\n        post_id\n    end\nend\n\n# Create post with tags atomically\npost_id = create_post_with_tags(driver, alice.id, \"Julia Tutorial\", \"Learn Julia!\", [\"julia\", \"tutorial\", \"programming\"])","category":"section"},{"location":"tutorial/#8.-Window-Functions","page":"Tutorial","title":"8. Window Functions","text":"Rank posts by number of comments:\n\nstruct PostRank\n    title::String\n    comment_count::Int64\n    rank::Int64\nend\n\nq = from(:posts) |>\n    join(:comments, col(:comments, :post_id) == col(:posts, :id); kind=:left) |>\n    group_by(col(:posts, :id), col(:posts, :title)) |>\n    select(NamedTuple,\n           col(:posts, :title),\n           count_star(),\n           row_number() |> over(order_by(count_star(); desc=true)))\n\nrankings = fetch_all(driver, q)","category":"section"},{"location":"tutorial/#9.-Advanced:-Subqueries","page":"Tutorial","title":"9. Advanced: Subqueries","text":"Find users who have commented on their own posts:\n\n# Subquery: posts where user commented\ncommented_own_posts = from(:comments) |>\n    join(:posts, col(:posts, :id) == col(:comments, :post_id); kind=:inner) |>\n    where(col(:comments, :user_id) == col(:posts, :user_id)) |>\n    select(NamedTuple, col(:posts, :user_id))\n\n# Main query: users who commented on own posts\nq = from(:users) |>\n    where(col(:users, :id) |> in_(subquery(commented_own_posts))) |>\n    select(User,\n           col(:users, :id),\n           col(:users, :email),\n           col(:users, :username),\n           col(:users, :created_at))\n\nusers = fetch_all(driver, q)","category":"section"},{"location":"tutorial/#10.-Cleanup","page":"Tutorial","title":"10. Cleanup","text":"# Drop all tables (in correct order due to foreign keys)\nexecute(driver, drop_table(:posts_tags))\nexecute(driver, drop_table(:comments))\nexecute(driver, drop_table(:posts))\nexecute(driver, drop_table(:tags))\nexecute(driver, drop_table(:users))","category":"section"},{"location":"tutorial/#11.-Performance:-Columnar-API-for-Analytics","page":"Tutorial","title":"11. Performance: Columnar API for Analytics","text":"For analytics queries on large datasets, use the columnar API for 8-10x speedup:\n\n# Define columnar struct (fields as Vectors)\nstruct SalesColumnar\n    amount::Vector{Float64}\n    quantity::Vector{Int}\n    product_name::Vector{String}\nend\n\n# Query large dataset\nsales_query = from(:sales) |>\n    join(:products, col(:products, :id) == col(:sales, :product_id)) |>\n    where(col(:sales, :date) >= param(Date, :start_date)) |>\n    select(NamedTuple,\n           col(:sales, :amount),\n           col(:sales, :quantity),\n           col(:products, :name))\n\n# Fetch in columnar format (8-10x faster than row-based!)\nsales = fetch_all_columnar(driver, sales_query, SalesColumnar, (start_date=Date(2024, 1, 1),))\n\n# Direct column operations (extremely fast)\ntotal_revenue = sum(sales.amount)\ntotal_quantity = sum(sales.quantity)\naverage_price = total_revenue / total_quantity\n\n# Convert to DataFrame for analysis\nusing DataFrames\ndf = DataFrame(\n    amount = sales.amount,\n    quantity = sales.quantity,\n    product = sales.product_name\n)\n\nWhen to use columnar API:\n\n✅ Large result sets (>1,000 rows)\n✅ Analytics and aggregations\n✅ Column-wise operations\n✅ DataFrame export\n\nWhen to use row-based API:\n\n✅ Small to medium result sets (<10,000 rows)\n✅ CRUD operations\n✅ Row-by-row iteration","category":"section"},{"location":"tutorial/#11.-High-Performance-Batch-Operations","page":"Tutorial","title":"11. High-Performance Batch Operations","text":"For bulk data insertion, SQLSketch provides insert_batch which automatically optimizes based on the database:\n\n# Generate test data (simulating bulk import)\ntest_users = [\n    (\n        id = uuid4(),\n        email = \"user$(i)@example.com\",\n        username = \"user$(i)\",\n        created_at = now()\n    )\n    for i in 1:10_000\n]\n\n# Batch insert - automatically uses PostgreSQL COPY for maximum performance\nresult = insert_batch(conn, dialect, registry, :users,\n                      [:id, :email, :username, :created_at],\n                      test_users)\n\nprintln(\"Inserted $(result.rowcount) users in bulk\")\n# → Inserted 10000 users in bulk\n\nPerformance comparison:\n\n# ❌ Slow: Loop INSERT (10,000 rows = ~455ms on PostgreSQL)\nfor user in test_users\n    q = insert_into(:users, [:id, :email, :username, :created_at]) |>\n        values(user)\n    execute(conn, dialect, registry, q)\nend\n\n# ✅ Fast: Batch INSERT (10,000 rows = ~0.2ms on PostgreSQL)\nresult = insert_batch(conn, dialect, registry, :users,\n                      [:id, :email, :username, :created_at],\n                      test_users)\n# → 2016x faster!\n\nKey benefits:\n\nAutomatic optimization: Uses PostgreSQL COPY when available, multi-row INSERT otherwise\nMassive speedup: 4x-2016x faster depending on batch size\nTransactional: Entire batch commits or rolls back atomically\nType-safe: Uses CodecRegistry for proper encoding\n\nSee benchmark/RESULTS.md in the repository for detailed performance analysis.","category":"section"},{"location":"tutorial/#Summary","page":"Tutorial","title":"Summary","text":"This tutorial covered:\n\n✅ Database schema creation with DDL\n✅ Type-safe data models\n✅ INSERT operations with RETURNING\n✅ SELECT queries with joins and filtering\n✅ UPDATE and DELETE operations\n✅ Parameterized queries\n✅ Aggregation and grouping\n✅ Transactions for data consistency\n✅ Window functions for analytics\n✅ Subqueries for complex filtering\n✅ High-performance columnar API\n✅ Batch operations for bulk data loading","category":"section"},{"location":"tutorial/#Next-Steps","page":"Tutorial","title":"Next Steps","text":"Explore API Reference for complete function documentation\nRead Design Philosophy to understand SQLSketch's architecture\nLearn about performance optimization in Performance Guide\nCheck out advanced PostgreSQL features (JSONB, Arrays, CTEs)\nBuild your own application with SQLSketch!","category":"section"}]
}
