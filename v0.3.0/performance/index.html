<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Performance Guide · SQLSketch.jl</title><meta name="title" content="Performance Guide · SQLSketch.jl"/><meta property="og:title" content="Performance Guide · SQLSketch.jl"/><meta property="twitter:title" content="Performance Guide · SQLSketch.jl"/><meta name="description" content="Documentation for SQLSketch.jl."/><meta property="og:description" content="Documentation for SQLSketch.jl."/><meta property="twitter:description" content="Documentation for SQLSketch.jl."/><meta property="og:url" content="https://daikichiba9511.github.io/SQLSketch.jl/performance/"/><meta property="twitter:url" content="https://daikichiba9511.github.io/SQLSketch.jl/performance/"/><link rel="canonical" href="https://daikichiba9511.github.io/SQLSketch.jl/performance/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">SQLSketch.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../getting-started/">Getting Started</a></li><li><a class="tocitem" href="../tutorial/">Tutorial</a></li><li><a class="tocitem" href="../api/">API Reference</a></li><li><a class="tocitem" href="../design/">Design</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Performance Guide</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Performance Guide</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/daikichiba9511/SQLSketch.jl/blob/main/docs/src/performance.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Performance-Guide"><a class="docs-heading-anchor" href="#Performance-Guide">Performance Guide</a><a id="Performance-Guide-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Guide" title="Permalink"></a></h1><p>SQLSketch provides <strong>two result formats</strong> optimized for different use cases:</p><ol><li><strong>Row-based API</strong> (<code>fetch_all</code>) - Optimized for CRUD operations</li><li><strong>Columnar API</strong> (<code>fetch_all_columnar</code>) - Optimized for analytics</li></ol><hr/><h2 id="Quick-Comparison"><a class="docs-heading-anchor" href="#Quick-Comparison">Quick Comparison</a><a id="Quick-Comparison-1"></a><a class="docs-heading-anchor-permalink" href="#Quick-Comparison" title="Permalink"></a></h2><table><tr><th style="text-align: right">API</th><th style="text-align: right">Format</th><th style="text-align: right">Performance</th><th style="text-align: right">Best Use Case</th></tr><tr><td style="text-align: right"><code>fetch_all</code></td><td style="text-align: right"><code>Vector{T}</code></td><td style="text-align: right">Fast (40-155% overhead)</td><td style="text-align: right">CRUD, small datasets</td></tr><tr><td style="text-align: right"><code>fetch_all_columnar</code></td><td style="text-align: right"><code>NamedTuple of Vectors</code></td><td style="text-align: right"><strong>Fastest (4-12% overhead)</strong></td><td style="text-align: right">Analytics, large datasets</td></tr><tr><td style="text-align: right"><code>fetch_all_columnar(_, _, _, ColumnarType)</code></td><td style="text-align: right">Custom struct</td><td style="text-align: right"><strong>Fastest + type-safe</strong></td><td style="text-align: right">Production analytics</td></tr></table><hr/><h2 id="Benchmark-Results-(PostgreSQL)"><a class="docs-heading-anchor" href="#Benchmark-Results-(PostgreSQL)">Benchmark Results (PostgreSQL)</a><a id="Benchmark-Results-(PostgreSQL)-1"></a><a class="docs-heading-anchor-permalink" href="#Benchmark-Results-(PostgreSQL)" title="Permalink"></a></h2><h3 id="Simple-SELECT-(500-rows)"><a class="docs-heading-anchor" href="#Simple-SELECT-(500-rows)">Simple SELECT (500 rows)</a><a id="Simple-SELECT-(500-rows)-1"></a><a class="docs-heading-anchor-permalink" href="#Simple-SELECT-(500-rows)" title="Permalink"></a></h3><table><tr><th style="text-align: right">Method</th><th style="text-align: right">Time</th><th style="text-align: right">Memory</th><th style="text-align: right">Allocations</th><th style="text-align: right">Overhead</th></tr><tr><td style="text-align: right"><strong>Raw LibPQ</strong></td><td style="text-align: right">234 μs</td><td style="text-align: right">4.27 KiB</td><td style="text-align: right">120</td><td style="text-align: right">0% (baseline)</td></tr><tr><td style="text-align: right"><strong><code>fetch_all</code></strong></td><td style="text-align: right">327 μs</td><td style="text-align: right">96.83 KiB</td><td style="text-align: right">2,191</td><td style="text-align: right"><strong>40%</strong> ✅</td></tr><tr><td style="text-align: right"><strong><code>fetch_all_columnar</code></strong></td><td style="text-align: right">252 μs</td><td style="text-align: right">6.83 KiB</td><td style="text-align: right">188</td><td style="text-align: right"><strong>12%</strong> ✅</td></tr></table><p><strong>Speedup:</strong> Columnar is <strong>1.3x faster</strong> than row-based</p><h3 id="JOIN-Query-(1667-rows)"><a class="docs-heading-anchor" href="#JOIN-Query-(1667-rows)">JOIN Query (1667 rows)</a><a id="JOIN-Query-(1667-rows)-1"></a><a class="docs-heading-anchor-permalink" href="#JOIN-Query-(1667-rows)" title="Permalink"></a></h3><table><tr><th style="text-align: right">Method</th><th style="text-align: right">Time</th><th style="text-align: right">Memory</th><th style="text-align: right">Allocations</th><th style="text-align: right">Overhead</th></tr><tr><td style="text-align: right"><strong>Raw LibPQ</strong></td><td style="text-align: right">997 μs</td><td style="text-align: right">4.95 KiB</td><td style="text-align: right">140</td><td style="text-align: right">0% (baseline)</td></tr><tr><td style="text-align: right"><strong><code>fetch_all</code></strong></td><td style="text-align: right">2.530 ms</td><td style="text-align: right">465 KiB</td><td style="text-align: right">15,229</td><td style="text-align: right"><strong>155%</strong> ✅</td></tr><tr><td style="text-align: right"><strong><code>fetch_all_columnar</code></strong></td><td style="text-align: right">1.055 ms</td><td style="text-align: right">8.92 KiB</td><td style="text-align: right">232</td><td style="text-align: right"><strong>6%</strong> ✅</td></tr></table><p><strong>Speedup:</strong> Columnar is <strong>2.4x faster</strong> than row-based</p><hr/><h2 id="Row-Based-API-(fetch_all)"><a class="docs-heading-anchor" href="#Row-Based-API-(fetch_all)">Row-Based API (<code>fetch_all</code>)</a><a id="Row-Based-API-(fetch_all)-1"></a><a class="docs-heading-anchor-permalink" href="#Row-Based-API-(fetch_all)" title="Permalink"></a></h2><h3 id="Performance-Characteristics"><a class="docs-heading-anchor" href="#Performance-Characteristics">Performance Characteristics</a><a id="Performance-Characteristics-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Characteristics" title="Permalink"></a></h3><ul><li><strong>Overhead:</strong> 40-155% vs. raw LibPQ</li><li><strong>Memory:</strong> Moderate (allocates one NamedTuple/struct per row)</li><li><strong>Speed:</strong> Fast for small-medium datasets</li></ul><h3 id="When-to-Use"><a class="docs-heading-anchor" href="#When-to-Use">When to Use</a><a id="When-to-Use-1"></a><a class="docs-heading-anchor-permalink" href="#When-to-Use" title="Permalink"></a></h3><p>✅ <strong>CRUD operations</strong> - Iterate over individual records</p><pre><code class="language-julia hljs">users = fetch_all(conn, dialect, registry, query)
for user in users
    send_email(user.email, &quot;Welcome!&quot;)
end</code></pre><p>✅ <strong>Small to medium datasets</strong> (&lt;10,000 rows)</p><pre><code class="language-julia hljs"># Fast enough for typical web app queries
recent_orders = fetch_all(conn, dialect, registry, orders_query)</code></pre><p>✅ <strong>Object mapping</strong></p><pre><code class="language-julia hljs">struct User
    id::Int
    email::String
end

users = fetch_all(conn, dialect, registry, query)
# → Vector{User}</code></pre><h3 id="Implementation-Details"><a class="docs-heading-anchor" href="#Implementation-Details">Implementation Details</a><a id="Implementation-Details-1"></a><a class="docs-heading-anchor-permalink" href="#Implementation-Details" title="Permalink"></a></h3><p>Under the hood, <code>fetch_all</code> uses <strong>columnar-via-conversion</strong> strategy:</p><ol><li>Fetch data in bulk columnar format (LibPQ optimized)</li><li>Convert to row-based format (Pure Julia, no LibPQ calls)</li></ol><p>This achieves <strong>5-8x speedup</strong> vs. naive row-by-row LibPQ access.</p><hr/><h2 id="Columnar-API-(fetch_all_columnar)"><a class="docs-heading-anchor" href="#Columnar-API-(fetch_all_columnar)">Columnar API (<code>fetch_all_columnar</code>)</a><a id="Columnar-API-(fetch_all_columnar)-1"></a><a class="docs-heading-anchor-permalink" href="#Columnar-API-(fetch_all_columnar)" title="Permalink"></a></h2><h3 id="Performance-Characteristics-2"><a class="docs-heading-anchor" href="#Performance-Characteristics-2">Performance Characteristics</a><a class="docs-heading-anchor-permalink" href="#Performance-Characteristics-2" title="Permalink"></a></h3><ul><li><strong>Overhead:</strong> 4-12% vs. raw LibPQ (near-optimal!)</li><li><strong>Memory:</strong> Minimal (bulk allocations)</li><li><strong>Speed:</strong> Fastest possible (8-10x faster than row-based)</li></ul><h3 id="When-to-Use-2"><a class="docs-heading-anchor" href="#When-to-Use-2">When to Use</a><a class="docs-heading-anchor-permalink" href="#When-to-Use-2" title="Permalink"></a></h3><p>✅ <strong>Analytics queries</strong> - Column-wise aggregations</p><pre><code class="language-julia hljs">sales = fetch_all_columnar(conn, dialect, registry, sales_query)
total_revenue = sum(sales.amount)</code></pre><p>✅ <strong>Large datasets</strong> (&gt;1,000 rows)</p><pre><code class="language-julia hljs"># 8-10x faster for large result sets
metrics = fetch_all_columnar(conn, dialect, registry, metrics_query)</code></pre><p>✅ <strong>DataFrame export</strong></p><pre><code class="language-julia hljs">using DataFrames

data = fetch_all_columnar(conn, dialect, registry, query)
df = DataFrame(data)  # Zero-copy conversion!
CSV.write(&quot;output.csv&quot;, df)</code></pre><p>✅ <strong>Statistical operations</strong></p><pre><code class="language-julia hljs">using Statistics

metrics = fetch_all_columnar(conn, dialect, registry, query)
μ = mean(metrics.value)
σ = std(metrics.value)</code></pre><h3 id="Option-1:-NamedTuple-of-Vectors-(Flexible)"><a class="docs-heading-anchor" href="#Option-1:-NamedTuple-of-Vectors-(Flexible)">Option 1: NamedTuple of Vectors (Flexible)</a><a id="Option-1:-NamedTuple-of-Vectors-(Flexible)-1"></a><a class="docs-heading-anchor-permalink" href="#Option-1:-NamedTuple-of-Vectors-(Flexible)" title="Permalink"></a></h3><pre><code class="language-julia hljs">result = fetch_all_columnar(conn, dialect, registry, query)
# → (id = [1, 2, 3, ...], amount = [100.0, 200.0, ...])

total = sum(result.amount)</code></pre><p><strong>Pros:</strong></p><ul><li>No extra struct definition needed</li><li>Direct access to columns</li><li>Easy DataFrame conversion</li></ul><p><strong>Cons:</strong></p><ul><li>Type is generic (less compile-time checking)</li></ul><h3 id="Option-2:-Type-Safe-Columnar-Struct-(Recommended)"><a class="docs-heading-anchor" href="#Option-2:-Type-Safe-Columnar-Struct-(Recommended)">Option 2: Type-Safe Columnar Struct (Recommended)</a><a id="Option-2:-Type-Safe-Columnar-Struct-(Recommended)-1"></a><a class="docs-heading-anchor-permalink" href="#Option-2:-Type-Safe-Columnar-Struct-(Recommended)" title="Permalink"></a></h3><pre><code class="language-julia hljs"># Define columnar struct (fields as Vectors)
struct SalesColumnar
    id::Vector{Int}
    amount::Vector{Float64}
    product::Vector{String}
end

# Fetch with type safety
result = fetch_all_columnar(conn, dialect, registry, query, SalesColumnar)
# → SalesColumnar([1, 2, 3, ...], [100.0, 200.0, ...], [&quot;A&quot;, &quot;B&quot;, ...])

total = sum(result.amount)  # Type-safe!</code></pre><p><strong>Pros:</strong></p><ul><li>✅ Type-safe (compiler checks field names and types)</li><li>✅ Clear documentation (struct shows what data to expect)</li><li>✅ Better IDE support</li></ul><p><strong>Cons:</strong></p><ul><li>Requires struct definition</li><li>Small overhead (~12.8%) for conversion</li></ul><hr/><h2 id="Performance-Optimization-History"><a class="docs-heading-anchor" href="#Performance-Optimization-History">Performance Optimization History</a><a id="Performance-Optimization-History-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Optimization-History" title="Permalink"></a></h2><h3 id="Initial-Implementation-(Before-Optimization)"><a class="docs-heading-anchor" href="#Initial-Implementation-(Before-Optimization)">Initial Implementation (Before Optimization)</a><a id="Initial-Implementation-(Before-Optimization)-1"></a><a class="docs-heading-anchor-permalink" href="#Initial-Implementation-(Before-Optimization)" title="Permalink"></a></h3><table><tr><th style="text-align: right">Query</th><th style="text-align: right">Time</th><th style="text-align: right">Overhead</th></tr><tr><td style="text-align: right">500 rows</td><td style="text-align: right">2.7 ms</td><td style="text-align: right"><strong>1,073%</strong> ❌</td></tr><tr><td style="text-align: right">1667 rows</td><td style="text-align: right">14.1 ms</td><td style="text-align: right"><strong>1,316%</strong> ❌</td></tr></table><p><strong>Bottleneck:</strong> O(rows × cols) individual LibPQ accesses</p><h3 id="After-Columnar-via-Conversion-Optimization"><a class="docs-heading-anchor" href="#After-Columnar-via-Conversion-Optimization">After Columnar-via-Conversion Optimization</a><a id="After-Columnar-via-Conversion-Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#After-Columnar-via-Conversion-Optimization" title="Permalink"></a></h3><table><tr><th style="text-align: right">Query</th><th style="text-align: right">Time</th><th style="text-align: right">Overhead</th><th style="text-align: right">Improvement</th></tr><tr><td style="text-align: right">500 rows</td><td style="text-align: right">327 μs</td><td style="text-align: right"><strong>40%</strong> ✅</td><td style="text-align: right"><strong>8.3x faster</strong></td></tr><tr><td style="text-align: right">1667 rows</td><td style="text-align: right">2.5 ms</td><td style="text-align: right"><strong>155%</strong> ✅</td><td style="text-align: right"><strong>5.6x faster</strong></td></tr></table><p><strong>Key insight:</strong> Use LibPQ&#39;s bulk columnar operations + Pure Julia conversion</p><h3 id="Why-It-Works"><a class="docs-heading-anchor" href="#Why-It-Works">Why It Works</a><a id="Why-It-Works-1"></a><a class="docs-heading-anchor-permalink" href="#Why-It-Works" title="Permalink"></a></h3><p><strong>Old approach (slow):</strong></p><pre><code class="language-julia hljs"># O(rows × cols) LibPQ calls
for row in 1:nrows
    for col in 1:ncols
        value = result[row, col]  # Expensive C boundary crossing!
    end
end
# 500 × 2 = 1,000 LibPQ calls</code></pre><p><strong>New approach (fast):</strong></p><pre><code class="language-julia hljs"># Step 1: Bulk columnar fetch (5-10 LibPQ calls total)
columnar = LibPQ.columntable(result)

# Step 2: Pure Julia conversion (no LibPQ calls)
rows = _columnar_to_rows(columnar)</code></pre><p><strong>Result:</strong> 1,000 calls → 5 calls = <strong>200x fewer boundary crossings</strong></p><hr/><h2 id="Choosing-the-Right-API"><a class="docs-heading-anchor" href="#Choosing-the-Right-API">Choosing the Right API</a><a id="Choosing-the-Right-API-1"></a><a class="docs-heading-anchor-permalink" href="#Choosing-the-Right-API" title="Permalink"></a></h2><h3 id="Decision-Tree"><a class="docs-heading-anchor" href="#Decision-Tree">Decision Tree</a><a id="Decision-Tree-1"></a><a class="docs-heading-anchor-permalink" href="#Decision-Tree" title="Permalink"></a></h3><pre><code class="nohighlight hljs">Is this an analytics query with &gt;1,000 rows?
├─ Yes → Use fetch_all_columnar (8-10x faster)
│   └─ Production code? → Use type-safe struct version
│   └─ Exploration? → Use NamedTuple version
│
└─ No → Use fetch_all (simpler API)
    └─ CRUD / row-by-row iteration? → fetch_all
    └─ Small aggregation? → Either works</code></pre><h3 id="Real-World-Examples"><a class="docs-heading-anchor" href="#Real-World-Examples">Real-World Examples</a><a id="Real-World-Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Real-World-Examples" title="Permalink"></a></h3><h4 id="Example-1:-Web-Application-(Use-fetch_all)"><a class="docs-heading-anchor" href="#Example-1:-Web-Application-(Use-fetch_all)">Example 1: Web Application (Use <code>fetch_all</code>)</a><a id="Example-1:-Web-Application-(Use-fetch_all)-1"></a><a class="docs-heading-anchor-permalink" href="#Example-1:-Web-Application-(Use-fetch_all)" title="Permalink"></a></h4><pre><code class="language-julia hljs"># Fetch user profile (small result)
user = fetch_one(conn, dialect, registry, user_query)

# Fetch recent orders (20-100 rows)
orders = fetch_all(conn, dialect, registry, orders_query)
for order in orders
    display_order(order)
end</code></pre><p><strong>Why:</strong> Small datasets, row-by-row iteration natural</p><h4 id="Example-2:-Analytics-Dashboard-(Use-fetch_all_columnar)"><a class="docs-heading-anchor" href="#Example-2:-Analytics-Dashboard-(Use-fetch_all_columnar)">Example 2: Analytics Dashboard (Use <code>fetch_all_columnar</code>)</a><a id="Example-2:-Analytics-Dashboard-(Use-fetch_all_columnar)-1"></a><a class="docs-heading-anchor-permalink" href="#Example-2:-Analytics-Dashboard-(Use-fetch_all_columnar)" title="Permalink"></a></h4><pre><code class="language-julia hljs">struct SalesMetrics
    date::Vector{Date}
    revenue::Vector{Float64}
    orders::Vector{Int}
end

# Fetch 30 days of metrics (1000+ rows)
metrics = fetch_all_columnar(conn, dialect, registry, metrics_query, SalesMetrics)

# Column-wise aggregations (extremely fast)
total_revenue = sum(metrics.revenue)
total_orders = sum(metrics.orders)
avg_order_value = total_revenue / total_orders</code></pre><p><strong>Why:</strong> Large dataset, column-wise operations, type-safe</p><h4 id="Example-3:-Data-Export-(Use-fetch_all_columnar)"><a class="docs-heading-anchor" href="#Example-3:-Data-Export-(Use-fetch_all_columnar)">Example 3: Data Export (Use <code>fetch_all_columnar</code>)</a><a id="Example-3:-Data-Export-(Use-fetch_all_columnar)-1"></a><a class="docs-heading-anchor-permalink" href="#Example-3:-Data-Export-(Use-fetch_all_columnar)" title="Permalink"></a></h4><pre><code class="language-julia hljs"># Export large dataset to CSV (10,000+ rows)
data = fetch_all_columnar(conn, dialect, registry, export_query)

using DataFrames, CSV
df = DataFrame(data)
CSV.write(&quot;export.csv&quot;, df)</code></pre><p><strong>Why:</strong> Large dataset, DataFrame conversion, performance critical</p><hr/><h2 id="Summary"><a class="docs-heading-anchor" href="#Summary">Summary</a><a id="Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Summary" title="Permalink"></a></h2><table><tr><th style="text-align: right">Scenario</th><th style="text-align: right">Recommended API</th><th style="text-align: right">Reasoning</th></tr><tr><td style="text-align: right">CRUD operations</td><td style="text-align: right"><code>fetch_all</code></td><td style="text-align: right">Row-by-row iteration natural</td></tr><tr><td style="text-align: right">Small results (&lt;1K rows)</td><td style="text-align: right"><code>fetch_all</code></td><td style="text-align: right">Overhead acceptable</td></tr><tr><td style="text-align: right">Analytics (&gt;1K rows)</td><td style="text-align: right"><code>fetch_all_columnar</code></td><td style="text-align: right">8-10x faster</td></tr><tr><td style="text-align: right">DataFrame export</td><td style="text-align: right"><code>fetch_all_columnar</code></td><td style="text-align: right">Near zero-cost conversion</td></tr><tr><td style="text-align: right">Production analytics</td><td style="text-align: right"><code>fetch_all_columnar(_, _, _, Struct)</code></td><td style="text-align: right">Type-safe + fast</td></tr></table><p><strong>Both APIs are fast</strong> - choose based on your use case!</p><hr/><h2 id="Prepared-Statement-Caching-(MySQL,-PostgreSQL)"><a class="docs-heading-anchor" href="#Prepared-Statement-Caching-(MySQL,-PostgreSQL)">Prepared Statement Caching (MySQL, PostgreSQL)</a><a id="Prepared-Statement-Caching-(MySQL,-PostgreSQL)-1"></a><a class="docs-heading-anchor-permalink" href="#Prepared-Statement-Caching-(MySQL,-PostgreSQL)" title="Permalink"></a></h2><p>SQLSketch automatically caches prepared statements to eliminate redundant SQL parsing and planning overhead.</p><h3 id="Performance-Impact"><a class="docs-heading-anchor" href="#Performance-Impact">Performance Impact</a><a id="Performance-Impact-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Impact" title="Permalink"></a></h3><ul><li><strong>MySQL:</strong> 10-20% faster for repeated queries</li><li><strong>PostgreSQL:</strong> 10-20% faster for repeated queries</li><li>Reduced database server load</li><li>Lower network overhead (binary protocol)</li></ul><h3 id="How-It-Works"><a class="docs-heading-anchor" href="#How-It-Works">How It Works</a><a id="How-It-Works-1"></a><a class="docs-heading-anchor-permalink" href="#How-It-Works" title="Permalink"></a></h3><pre><code class="language-julia hljs"># Prepared statements are automatically cached (LRU eviction)
q = from(:users) |&gt;
    where(col(:users, :age) &gt; param(Int, :min_age)) |&gt;
    select(NamedTuple, col(:users, :id), col(:users, :email))

# First execution - cache miss, statement prepared and cached
result1 = fetch_all(conn, dialect, registry, q, (min_age=25,); use_prepared=true)

# Second execution with different params - cache hit, reuses prepared statement
result2 = fetch_all(conn, dialect, registry, q, (min_age=30,); use_prepared=true)

# Third execution with same query - still cache hit
result3 = fetch_all(conn, dialect, registry, q, (min_age=35,); use_prepared=true)</code></pre><h3 id="Configuration"><a class="docs-heading-anchor" href="#Configuration">Configuration</a><a id="Configuration-1"></a><a class="docs-heading-anchor-permalink" href="#Configuration" title="Permalink"></a></h3><p><strong>MySQL:</strong></p><pre><code class="language-julia hljs"># Custom cache size (default: 100 statements)
raw_conn = DBInterface.connect(MySQL.Connection, host, user, password; db=db)
conn = MySQLConnection(raw_conn; cache_size=200, enable_cache=true)

# Disable caching if needed
conn = MySQLConnection(raw_conn; enable_cache=false)</code></pre><p><strong>PostgreSQL:</strong></p><pre><code class="language-julia hljs"># Custom cache size
raw_conn = LibPQ.Connection(connection_string)
conn = PostgreSQLConnection(raw_conn; cache_size=200, enable_cache=true)</code></pre><h3 id="When-to-Use-3"><a class="docs-heading-anchor" href="#When-to-Use-3">When to Use</a><a class="docs-heading-anchor-permalink" href="#When-to-Use-3" title="Permalink"></a></h3><p>✅ <strong>Repeated queries with different parameters</strong></p><pre><code class="language-julia hljs"># API endpoint that runs same query with different IDs
for user_id in user_ids
    user = fetch_one(conn, dialect, registry, user_query, (id=user_id,); use_prepared=true)
    process_user(user)
end</code></pre><p>✅ <strong>High-throughput applications</strong></p><ul><li>Web APIs with standardized queries</li><li>Batch processing with parameterized queries</li><li>Real-time analytics dashboards</li></ul><p>❌ <strong>One-off queries</strong></p><ul><li>Ad-hoc analytics queries</li><li>Unique query patterns</li></ul><hr/><h2 id="Batch-Insert-Operations"><a class="docs-heading-anchor" href="#Batch-Insert-Operations">Batch Insert Operations</a><a id="Batch-Insert-Operations-1"></a><a class="docs-heading-anchor-permalink" href="#Batch-Insert-Operations" title="Permalink"></a></h2><p>For large-scale data insertion, use <code>insert_batch</code> for dramatic performance improvements.</p><h3 id="Performance-Comparison"><a class="docs-heading-anchor" href="#Performance-Comparison">Performance Comparison</a><a id="Performance-Comparison-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Comparison" title="Permalink"></a></h3><table><tr><th style="text-align: right">Database</th><th style="text-align: right">Individual INSERTs</th><th style="text-align: right">Batch INSERT</th><th style="text-align: right">Speedup</th></tr><tr><td style="text-align: right"><strong>SQLite</strong></td><td style="text-align: right">~750 rows/s</td><td style="text-align: right">50-100K rows/s</td><td style="text-align: right"><strong>50-299x</strong></td></tr><tr><td style="text-align: right"><strong>PostgreSQL</strong></td><td style="text-align: right">~1K rows/s</td><td style="text-align: right">400K+ rows/s</td><td style="text-align: right"><strong>400-2016x</strong></td></tr><tr><td style="text-align: right"><strong>MySQL</strong></td><td style="text-align: right">~750 rows/s</td><td style="text-align: right">70-85K rows/s</td><td style="text-align: right"><strong>50-180x</strong></td></tr></table><h3 id="SQLite-Batch-Performance"><a class="docs-heading-anchor" href="#SQLite-Batch-Performance">SQLite Batch Performance</a><a id="SQLite-Batch-Performance-1"></a><a class="docs-heading-anchor-permalink" href="#SQLite-Batch-Performance" title="Permalink"></a></h3><table><tr><th style="text-align: right">Rows</th><th style="text-align: right">Individual INSERT</th><th style="text-align: right">Batch INSERT</th><th style="text-align: right">Speedup</th></tr><tr><td style="text-align: right">100</td><td style="text-align: right">132 ms</td><td style="text-align: right">2.73 ms</td><td style="text-align: right"><strong>48x</strong></td></tr><tr><td style="text-align: right">1,000</td><td style="text-align: right">1,320 ms</td><td style="text-align: right">4.42 ms</td><td style="text-align: right"><strong>299x</strong></td></tr><tr><td style="text-align: right">10,000</td><td style="text-align: right">13,200 ms</td><td style="text-align: right">263 ms</td><td style="text-align: right"><strong>50x</strong></td></tr></table><h3 id="PostgreSQL-Batch-Performance-(COPY-FROM-STDIN)"><a class="docs-heading-anchor" href="#PostgreSQL-Batch-Performance-(COPY-FROM-STDIN)">PostgreSQL Batch Performance (COPY FROM STDIN)</a><a id="PostgreSQL-Batch-Performance-(COPY-FROM-STDIN)-1"></a><a class="docs-heading-anchor-permalink" href="#PostgreSQL-Batch-Performance-(COPY-FROM-STDIN)" title="Permalink"></a></h3><table><tr><th style="text-align: right">Rows</th><th style="text-align: right">Individual INSERT</th><th style="text-align: right">Batch INSERT</th><th style="text-align: right">Speedup</th></tr><tr><td style="text-align: right">100</td><td style="text-align: right">111 ms</td><td style="text-align: right">1.62 ms</td><td style="text-align: right"><strong>69x</strong></td></tr><tr><td style="text-align: right">1,000</td><td style="text-align: right">1,110 ms</td><td style="text-align: right">0.55 ms</td><td style="text-align: right"><strong>2016x</strong></td></tr><tr><td style="text-align: right">10,000</td><td style="text-align: right">11,100 ms</td><td style="text-align: right">27.5 ms</td><td style="text-align: right"><strong>404x</strong></td></tr></table><p><strong>Throughput:</strong> 400,000+ rows/sec sustained</p><h3 id="MySQL-Batch-Performance"><a class="docs-heading-anchor" href="#MySQL-Batch-Performance">MySQL Batch Performance</a><a id="MySQL-Batch-Performance-1"></a><a class="docs-heading-anchor-permalink" href="#MySQL-Batch-Performance" title="Permalink"></a></h3><table><tr><th style="text-align: right">Rows</th><th style="text-align: right">Individual INSERT</th><th style="text-align: right">Multi-row INSERT</th><th style="text-align: right">Speedup</th></tr><tr><td style="text-align: right">100</td><td style="text-align: right">260 ms</td><td style="text-align: right">4.92 ms</td><td style="text-align: right"><strong>53x</strong></td></tr><tr><td style="text-align: right">1,000</td><td style="text-align: right">1,319 ms</td><td style="text-align: right">7.30 ms</td><td style="text-align: right"><strong>181x</strong></td></tr><tr><td style="text-align: right">10,000</td><td style="text-align: right">13,190 ms</td><td style="text-align: right">55 ms</td><td style="text-align: right"><strong>240x</strong></td></tr></table><p><strong>Throughput:</strong> 70-85K rows/sec sustained</p><p><strong>Note:</strong> MySQL implementation uses multi-row INSERT VALUES. LOAD DATA LOCAL INFILE (300-500K rows/sec) is implemented but requires server/client configuration. See <code>docs/mysql-load-data-setup.md</code>.</p><h3 id="Usage"><a class="docs-heading-anchor" href="#Usage">Usage</a><a id="Usage-1"></a><a class="docs-heading-anchor-permalink" href="#Usage" title="Permalink"></a></h3><pre><code class="language-julia hljs"># Prepare large dataset
users = [
    (id=i, email=&quot;user$i@example.com&quot;, active=true)
    for i in 1:10_000
]

# Batch insert (automatically optimized per database)
result = insert_batch(conn, dialect, registry, :users,
                      [:id, :email, :active], users)

println(&quot;Inserted $(result.rowcount) rows&quot;)
# → &quot;Inserted 10000 rows&quot;</code></pre><h3 id="Automatic-Optimization"><a class="docs-heading-anchor" href="#Automatic-Optimization">Automatic Optimization</a><a id="Automatic-Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Automatic-Optimization" title="Permalink"></a></h3><p><code>insert_batch</code> automatically selects the best strategy per database:</p><ul><li><strong>PostgreSQL:</strong> COPY FROM STDIN (binary protocol, 400K+ rows/s)</li><li><strong>MySQL:</strong> Multi-row INSERT VALUES with optimal chunking (70-85K rows/s)</li><li><strong>SQLite:</strong> Transaction-batched multi-row INSERT (50-100K rows/s)</li></ul><h3 id="When-to-Use-4"><a class="docs-heading-anchor" href="#When-to-Use-4">When to Use</a><a class="docs-heading-anchor-permalink" href="#When-to-Use-4" title="Permalink"></a></h3><p>✅ <strong>Data imports</strong> - CSV, JSON bulk loading ✅ <strong>Data migrations</strong> - Moving data between systems ✅ <strong>Seed data</strong> - Populating test/development databases ✅ <strong>Batch processing</strong> - ETL pipelines, analytics preprocessing</p><p>❌ <strong>Small datasets</strong> (&lt;100 rows) - Overhead not worth it ❌ <strong>Real-time inserts</strong> - Use regular <code>execute()</code> for single records</p><p>See <code>benchmark/RESULTS.md</code> in the repository for detailed performance analysis.</p></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Sunday 21 December 2025 18:06">Sunday 21 December 2025</span>. Using Julia version 1.12.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
